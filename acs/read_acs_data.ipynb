{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data for sequence 10...\n",
      "Importing data for sequence 20...\n",
      "Importing data for sequence 30...\n",
      "Importing data for sequence 40...\n",
      "Importing data for sequence 50...\n",
      "Importing data for sequence 60...\n",
      "Importing data for sequence 70...\n",
      "Importing data for sequence 80...\n",
      "Importing data for sequence 90...\n",
      "Importing data for sequence 100...\n",
      "Importing data for sequence 110...\n",
      "Importing data for sequence 120...\n",
      "Importing data for sequence 130...\n",
      "Importing data for sequence 140...\n",
      "Importing data for sequence 150...\n",
      "Importing data for sequence 160...\n",
      "Importing data for sequence 166...\n",
      "Writing variables file...\n",
      "Writing data (estimates) file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install xlrd\n",
    "\n",
    "debug = 1\n",
    "import numpy as np\n",
    "import pandas\n",
    "#from SciServer import CasJobs\n",
    "#from pprint import pprint\n",
    "\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "states = ['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc']\n",
    "states += ['de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in']\n",
    "states += ['ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn']\n",
    "states += ['mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj']\n",
    "states += ['nm', 'nv', 'ny', 'oh', 'ok', 'or']\n",
    "states += ['pa', 'pr', 'ri', 'sc', 'sd', 'tn', 'tx', 'us']\n",
    "states += ['ut' ,'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
    "\n",
    "data_df = pandas.DataFrame()\n",
    "metadata_df = pandas.DataFrame()\n",
    "error_df = pandas.DataFrame()\n",
    "\n",
    "# 1-6, 139-150\n",
    "want_sequences = []\n",
    "#for i in range(1,7):\n",
    "#    want_sequences.append(i)\n",
    "#for i in range(139,151):\n",
    "#    want_sequences.append(i)\n",
    "for i in range(1,167):\n",
    "    want_sequences.append(i)\n",
    "\n",
    "for i in want_sequences:\n",
    "    if (debug >= 1):\n",
    "        if ((np.mod(i, 10) == 0) | (i == len(want_sequences))):\n",
    "            print('Importing data for sequence {0:,.0f}...'.format(i))\n",
    "    this_seq_data_df = pandas.DataFrame()\n",
    "    this_seq_metadata_filename = '/home/idies/workspace/raddick_acs_data/metadata/Seq{0:.0f}.xls'.format(i)\n",
    "    this_seq_metadata_in_cols_df = pandas.read_excel(this_seq_metadata_filename, header=None, encoding='utf-8')\n",
    "    this_seq_metadata_in_cols_df = this_seq_metadata_in_cols_df.dropna(axis=1)\n",
    "    \n",
    "    if (i == 1):\n",
    "        this_seq_metadata_in_cols_df.columns = ['FILEID','FILETYPE','STUSAB','CHARITER','SEQUENCE','LOGRECNO','B00001_001_UW','B00001_002_UW']\n",
    "    else:\n",
    "        this_seq_metadata_in_cols_df.columns = this_seq_metadata_in_cols_df.loc[0]\n",
    "\n",
    "    this_seq_metadata_df = this_seq_metadata_in_cols_df.T\n",
    "    this_seq_metadata_df.columns = ['variable', 'description']\n",
    "    if (i == 1):\n",
    "        this_seq_metadata_df['variable'] = this_seq_metadata_in_cols_df.columns\n",
    "        this_seq_metadata_df['sequence_number'] = [0,0,0,0,0,0,1,1] \n",
    "    else:\n",
    "        this_seq_metadata_df['sequence_number'] = i\n",
    "    \n",
    "    for onestate in states:\n",
    "        statefilename = '/home/idies/workspace/raddick_acs_data/data/e20161{1:s}{2:04d}000.txt'.format(i,onestate,i)\n",
    "        onestate_df = pandas.read_csv(statefilename, header=None, sep=',', encoding='utf-8')\n",
    "        this_seq_data_df = this_seq_data_df.append(onestate_df)\n",
    "        \n",
    "    this_seq_data_df.columns = this_seq_metadata_in_cols_df.columns\n",
    "    \n",
    "    this_seq_data_df = this_seq_data_df.drop(['SEQUENCE'], axis=1)\n",
    "    if (i >= 2):\n",
    "        this_seq_metadata_df = this_seq_metadata_df.drop(['FILEID','FILETYPE','STUSAB', 'SEQUENCE', 'CHARITER','LOGRECNO'], axis=0)\n",
    "        this_seq_data_df = this_seq_data_df.drop(['FILEID','FILETYPE','STUSAB', 'CHARITER', 'LOGRECNO'], axis=1)\n",
    "\n",
    "    if (debug >= 2):\n",
    "        print('Merging datasets...')\n",
    "    metadata_df = pandas.concat((metadata_df, this_seq_metadata_df), axis=0)\n",
    "    data_df = pandas.concat((data_df, this_seq_data_df), axis=1)\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Creating pseudo geoid...')\n",
    "data_df['PSEUDO_GEOID'] = data_df['STUSAB'].str.upper() + data_df['LOGRECNO'].apply(lambda x: '{0:07d}'.format(x))\n",
    "\n",
    "#metadata_df.loc['PSEUDO_GEOID'] = ['PSEUDO_GEOID', 'Temporary ID constructed from the STUSAB and the 7-digit zero-padded LOGRECNO to use to look up the geoid later.', 0]\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Indexing...')\n",
    "data_df = data_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Reading geography file...')\n",
    "geoid_df = pandas.read_excel('metadata/geoid.xlsx', encoding='utf-8')\n",
    "geoid_df = geoid_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Merging geography with data...')\n",
    "data_df = data_df.join(geoid_df[['GEOID','NAME']])\n",
    "#data_df = data_df.rename(columns={'NAME': 'GEO_NAME'})\n",
    "\n",
    "#metadata_df['GEOID'] = 'Geography identifier'\n",
    "#metadata_df['NAME'] = 'Name of geography unit'\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Resetting index...')\n",
    "#metadata_df = metadata_df.set_index('GEOID')\n",
    "\n",
    "metadata_df.loc['GEOID'] = ['GEOID', 'Geography identifier (also functions as index of data tables)', 0]\n",
    "metadata_df.loc['NAME'] = ['NAME', 'Name of geography region', 0]\n",
    "\n",
    "data_df = data_df.set_index('GEOID', drop=False)\n",
    "data_df.index.name = ''\n",
    "\n",
    "#metadata_df = metadata_df.set_index('variable', drop=False)\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing variables file...')\n",
    "metadata_df.to_csv('/home/idies/workspace/raddick_acs_data/variables_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing data (estimates) file...')\n",
    "data_df.to_csv('/home/idies/workspace/raddick_acs_data/data_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Done!')\n",
    "\n",
    "#data_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing errors for sequence 10...\n",
      "Importing errors for sequence 20...\n",
      "Importing errors for sequence 30...\n",
      "Importing errors for sequence 40...\n",
      "Importing errors for sequence 50...\n",
      "Importing errors for sequence 60...\n",
      "Importing errors for sequence 70...\n",
      "Importing errors for sequence 80...\n",
      "Importing errors for sequence 90...\n",
      "Importing errors for sequence 100...\n",
      "Importing errors for sequence 110...\n",
      "Importing errors for sequence 120...\n",
      "Importing errors for sequence 130...\n",
      "Importing errors for sequence 140...\n",
      "Importing errors for sequence 150...\n",
      "Importing errors for sequence 160...\n",
      "Importing errors for sequence 166...\n",
      "Writing margins of error file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "debug =1\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "states = ['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc']\n",
    "states += ['de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in']\n",
    "states += ['ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn']\n",
    "states += ['mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj']\n",
    "states += ['nm', 'nv', 'ny', 'oh', 'ok', 'or']\n",
    "states += ['pa', 'pr', 'ri', 'sc', 'sd', 'tn', 'tx', 'us']\n",
    "states += ['ut' ,'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
    "\n",
    "data_df = pandas.DataFrame()\n",
    "metadata_df = pandas.DataFrame()\n",
    "error_df = pandas.DataFrame()\n",
    "\n",
    "# 1-6, 139-150\n",
    "want_sequences = []\n",
    "#for i in range(1,7):\n",
    "#    want_sequences.append(i)\n",
    "#for i in range(139,151):\n",
    "#    want_sequences.append(i)\n",
    "for i in range(1,167):\n",
    "    want_sequences.append(i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in want_sequences:\n",
    "    if (debug >= 1):\n",
    "        if ((np.mod(i, 10) == 0) | (i == len(want_sequences))):\n",
    "            print('Importing errors for sequence {0:,.0f}...'.format(i))\n",
    "    this_seq_error_df = pandas.DataFrame()\n",
    "    this_seq_metadata_filename = '/home/idies/workspace/raddick_acs_data/metadata/Seq{0:.0f}.xls'.format(i)\n",
    "    this_seq_metadata_in_cols_df = pandas.read_excel(this_seq_metadata_filename, header=None, encoding='utf-8')\n",
    "    this_seq_metadata_in_cols_df = this_seq_metadata_in_cols_df.dropna(axis=1)\n",
    "    \n",
    "    if (i == 1):\n",
    "        this_seq_metadata_in_cols_df.columns = ['FILEID','FILETYPE','STUSAB','CHARITER','SEQUENCE','LOGRECNO','B00001_001_UW','B00001_002_UW']\n",
    "    else:\n",
    "        this_seq_metadata_in_cols_df.columns = this_seq_metadata_in_cols_df.loc[0]\n",
    "\n",
    "    this_seq_metadata_df = this_seq_metadata_in_cols_df.T\n",
    "    this_seq_metadata_df.columns = ['variable', 'description']\n",
    "    if (i == 1):\n",
    "        this_seq_metadata_df['variable'] = this_seq_metadata_in_cols_df.columns\n",
    "        this_seq_metadata_df['sequence_number'] = [0,0,0,0,0,0,1,1] \n",
    "    else:\n",
    "        this_seq_metadata_df['sequence_number'] = i\n",
    "    \n",
    "    for onestate in states:\n",
    "        statefilename = '/home/idies/workspace/raddick_acs_data/data/m20161{1:s}{2:04d}000.txt'.format(i,onestate,i)\n",
    "        onestate_df = pandas.read_csv(statefilename, header=None, sep=',', encoding='utf-8')\n",
    "        this_seq_error_df = this_seq_error_df.append(onestate_df)\n",
    "        \n",
    "    this_seq_error_df.columns = this_seq_metadata_in_cols_df.columns\n",
    "    \n",
    "    this_seq_error_df = this_seq_error_df.drop(['SEQUENCE'], axis=1)\n",
    "    if (i >= 2):\n",
    "        this_seq_metadata_df = this_seq_metadata_df.drop(['FILEID','FILETYPE','STUSAB', 'SEQUENCE', 'CHARITER','LOGRECNO'], axis=0)\n",
    "        this_seq_error_df = this_seq_error_df.drop(['FILEID','FILETYPE','STUSAB', 'CHARITER', 'LOGRECNO'], axis=1)\n",
    "\n",
    "#    if (debug >= 2):\n",
    "#        print('Merging datasets...')\n",
    "    metadata_df = pandas.concat((metadata_df, this_seq_metadata_df), axis=0)\n",
    "    error_df = pandas.concat((error_df, this_seq_error_df), axis=1)\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Creating pseudo geoid...')\n",
    "error_df['PSEUDO_GEOID'] = error_df['STUSAB'].str.upper() + error_df['LOGRECNO'].apply(lambda x: '{0:07d}'.format(x))\n",
    "\n",
    "#metadata_df.loc['PSEUDO_GEOID'] = ['PSEUDO_GEOID', 'Temporary ID constructed from the STUSAB and the 7-digit zero-padded LOGRECNO to use to look up the geoid later.', 0]\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Indexing...')\n",
    "error_df = error_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Reading geography file...')\n",
    "geoid_df = pandas.read_excel('metadata/geoid.xlsx', encoding='utf-8')\n",
    "geoid_df = geoid_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Merging geography with data...')\n",
    "error_df = error_df.join(geoid_df[['GEOID','NAME']])\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Resetting index...')\n",
    "#metadata_df = metadata_df.set_index('GEOID')\n",
    "\n",
    "metadata_df.loc['GEOID'] = ['GEOID', 'Geography identifier (also functions as index of data tables)', 0]\n",
    "metadata_df.loc['NAME'] = ['NAME', 'Name of geography region', 0]\n",
    "\n",
    "error_df = error_df.set_index('GEOID', drop=False)\n",
    "error_df.index.name = ''\n",
    "\n",
    "#metadata_df = metadata_df.set_index('variable', drop=False)\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing margins of error file...')\n",
    "error_df.to_csv('/home/idies/workspace/raddick_acs_data/error_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing geography data...\n",
      "Writing geography variables file...\n",
      "Writing geography file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "geo_df = pandas.DataFrame()\n",
    "geo_metadata_df = pandas.DataFrame()\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Importing geography data...')\n",
    "\n",
    "geo_metadata_filename = '/home/idies/workspace/raddick_acs_data/metadata/2016_SFGeoFileTemplate.xls'\n",
    "geo_metadata_df = pandas.read_excel(geo_metadata_filename, header=None, encoding='utf-8')\n",
    "geo_metadata_df = geo_metadata_df.dropna(axis=1)\n",
    "geo_metadata_df.columns = geo_metadata_df.loc[0]\n",
    "geo_metadata_df = geo_metadata_df.drop(0, axis=0)\n",
    "geo_metadata_df.index = ['description']\n",
    "\n",
    "for onestate in states:\n",
    "    statefilename = 'geography/g20161{0:}.csv'.format(onestate)\n",
    "    if (debug >= 2):\n",
    "        print(statefilename)\n",
    "    onestate_df = pandas.read_csv(statefilename, header=None, encoding='utf-8')\n",
    "    geo_df = geo_df.append(onestate_df)\n",
    "\n",
    "geo_df.columns = geo_metadata_df.columns\n",
    "geo_df = geo_df.set_index('GEOID', drop=False)\n",
    "geo_df.index.name = ''\n",
    "\n",
    "geo_metadata_df = geo_metadata_df.T\n",
    "geo_metadata_df = geo_metadata_df.reset_index()\n",
    "geo_metadata_df.columns = ['variable', 'description']\n",
    "geo_metadata_df = geo_metadata_df.set_index('variable', drop=False)\n",
    "geo_metadata_df.index.name = ''\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing geography variables file...')\n",
    "geo_metadata_df.to_csv('/home/idies/workspace/raddick_acs_data/geo_variables_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing geography file...')\n",
    "geo_df.to_csv('/home/idies/workspace/raddick_acs_data/geo_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# reorder columns\n",
    "#new_column_list = []\n",
    "#new_column_list.append(geo_metadata_df.columns[len(geo_metadata_df.columns)-5])\n",
    "#for i in range(0,len(geo_metadata_df.columns)-5):\n",
    "#    new_column_list.append(geo_metadata_df.columns[i])\n",
    "#for j in range(len(geo_metadata_df.columns)-4, len(geo_metadata_df.columns)):\n",
    "#    new_column_list.append(geo_metadata_df.columns[j])\n",
    "#geo_metadata_df.columns = new_column_list\n",
    "\n",
    "#new_column_list = []\n",
    "#new_column_list.append(geo_df.columns[len(geo_df.columns)-5])\n",
    "#for i in range(0,len(geo_df.columns)-5):\n",
    "#    new_column_list.append(geo_df.columns[i])\n",
    "#for j in range(len(geo_df.columns)-4, len(geo_df.columns)):\n",
    "#    new_column_list.append(geo_df.columns[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print('Females under age 5 in Baltimore County: {0:,.0f} with margin of error {1:,.0f}'.format(data_df['B01001_027'].loc['05000US24510'], error_df['B01001_027'].loc['05000US24510']))\n",
    "#data_df['B01001_027'].loc['05000US24510']\n",
    "#error_df['B01001_027'].loc['05000US24510']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
