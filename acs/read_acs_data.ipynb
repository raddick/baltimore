{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data for sequence 20...\n",
      "Importing data for sequence 40...\n",
      "Importing data for sequence 60...\n",
      "Importing data for sequence 80...\n",
      "Importing data for sequence 100...\n",
      "Importing data for sequence 120...\n",
      "Importing data for sequence 140...\n",
      "Importing data for sequence 160...\n",
      "Importing data for sequence 165...\n",
      "Writing variables file...\n",
      "Writing data (estimates) file...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/home/idies/anaconda3/lib/python3.5/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/idies/anaconda3/lib/python3.5/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/idies/anaconda3/lib/python3.5/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1592\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mcol_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1593\u001b[0m                 \u001b[0;31m# self.data is a preallocated list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-599819806d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Writing data (estimates) file...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/idies/workspace/raddick_acs_data/data_acs2016.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/idies/anaconda3/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/idies/anaconda3/lib/python3.5/site-packages/pandas/formats/format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1478\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1479\u001b[0;31m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1481\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_save_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install xlrd\n",
    "\n",
    "debug = 1\n",
    "import numpy as np\n",
    "import pandas\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "states = ['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc']\n",
    "states += ['de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in']\n",
    "states += ['ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn']\n",
    "states += ['mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj']\n",
    "states += ['nm', 'nv', 'ny', 'oh', 'ok', 'or']\n",
    "states += ['pa', 'pr', 'ri', 'sc', 'sd', 'tn', 'tx', 'us']\n",
    "states += ['ut' ,'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
    "\n",
    "data_df = pandas.DataFrame()\n",
    "metadata_df = pandas.DataFrame()\n",
    "error_df = pandas.DataFrame()\n",
    "\n",
    "# 1-6, 139-150\n",
    "want_sequences = []\n",
    "#for i in range(1,7):\n",
    "#    want_sequences.append(i)\n",
    "#for i in range(139,151):\n",
    "#    want_sequences.append(i)\n",
    "for i in range(1,167):\n",
    "    want_sequences.append(i)\n",
    "\n",
    "for i in want_sequences:\n",
    "    if (debug >= 1):\n",
    "        if ((np.mod(i, 20) == 0) | (i == len(want_sequences))):\n",
    "            print('Importing data for sequence {0:,.0f}...'.format(i))\n",
    "    this_seq_data_df = pandas.DataFrame()\n",
    "    this_seq_metadata_filename = '/home/idies/workspace/raddick_acs_data/metadata/Seq{0:.0f}.xls'.format(i)\n",
    "    this_seq_metadata_in_cols_df = pandas.read_excel(this_seq_metadata_filename, header=None, encoding='utf-8')\n",
    "    this_seq_metadata_in_cols_df = this_seq_metadata_in_cols_df.dropna(axis=1)\n",
    "    \n",
    "    if (i == 1):\n",
    "        this_seq_metadata_in_cols_df.columns = ['FILEID','FILETYPE','STUSAB','CHARITER','SEQUENCE','LOGRECNO','B00001_001_UW','B00001_002_UW']\n",
    "    else:\n",
    "        this_seq_metadata_in_cols_df.columns = this_seq_metadata_in_cols_df.loc[0]\n",
    "\n",
    "    this_seq_metadata_df = this_seq_metadata_in_cols_df.T\n",
    "    this_seq_metadata_df.columns = ['variable', 'description']\n",
    "    if (i == 1):\n",
    "        this_seq_metadata_df['variable'] = this_seq_metadata_in_cols_df.columns\n",
    "        this_seq_metadata_df['sequence_number'] = [0,0,0,0,0,0,1,1] \n",
    "    else:\n",
    "        this_seq_metadata_df['sequence_number'] = i\n",
    "    \n",
    "    for onestate in states:\n",
    "        statefilename = '/home/idies/workspace/raddick_acs_data/data/seq{0:.0f}/e20161{1:s}{2:04d}000.txt'.format(i,onestate,i)\n",
    "        onestate_df = pandas.read_csv(statefilename, header=None, sep=',', encoding='utf-8')\n",
    "        this_seq_data_df = this_seq_data_df.append(onestate_df)\n",
    "        \n",
    "    this_seq_data_df.columns = this_seq_metadata_in_cols_df.columns\n",
    "    \n",
    "    this_seq_data_df = this_seq_data_df.drop(['SEQUENCE'], axis=1)\n",
    "    if (i >= 2):\n",
    "        this_seq_metadata_df = this_seq_metadata_df.drop(['FILEID','FILETYPE','STUSAB', 'SEQUENCE', 'CHARITER','LOGRECNO'], axis=0)\n",
    "        this_seq_data_df = this_seq_data_df.drop(['FILEID','FILETYPE','STUSAB', 'CHARITER', 'LOGRECNO'], axis=1)\n",
    "\n",
    "    if (debug >= 2):\n",
    "        print('Merging datasets...')\n",
    "    metadata_df = pandas.concat((metadata_df, this_seq_metadata_df), axis=0)\n",
    "    data_df = pandas.concat((data_df, this_seq_data_df), axis=1)\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Creating pseudo geoid...')\n",
    "data_df['PSEUDO_GEOID'] = data_df['STUSAB'].str.upper() + data_df['LOGRECNO'].apply(lambda x: '{0:07d}'.format(x))\n",
    "\n",
    "#metadata_df.loc['PSEUDO_GEOID'] = ['PSEUDO_GEOID', 'Temporary ID constructed from the STUSAB and the 7-digit zero-padded LOGRECNO to use to look up the geoid later.', 0]\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Indexing...')\n",
    "data_df = data_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Reading geography file...')\n",
    "geoid_df = pandas.read_excel('metadata/geoid.xlsx', encoding='utf-8')\n",
    "geoid_df = geoid_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Merging geography with data...')\n",
    "data_df = data_df.join(geoid_df[['GEOID','NAME']])\n",
    "#data_df = data_df.rename(columns={'NAME': 'GEO_NAME'})\n",
    "\n",
    "#metadata_df['GEOID'] = 'Geography identifier'\n",
    "#metadata_df['NAME'] = 'Name of geography unit'\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Resetting index...')\n",
    "#metadata_df = metadata_df.set_index('GEOID')\n",
    "\n",
    "metadata_df.loc['GEOID'] = ['GEOID', 'Geography identifier (also functions as index of data tables)', 0]\n",
    "metadata_df.loc['NAME'] = ['NAME', 'Name of geography region', 0]\n",
    "\n",
    "data_df = data_df.set_index('GEOID', drop=False)\n",
    "data_df.index.name = ''\n",
    "\n",
    "#metadata_df = metadata_df.set_index('variable', drop=False)\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing variables file...')\n",
    "metadata_df.to_csv('/home/idies/workspace/raddick_acs_data/variables_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing data (estimates) file...')\n",
    "data_df.to_csv('/home/idies/workspace/raddick_acs_data/data_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Done!')\n",
    "\n",
    "\n",
    "    \n",
    "for i in want_sequences:\n",
    "    if (debug >= 1):\n",
    "        if ((np.mod(i, 20) == 0) | (i == len(want_sequences))):\n",
    "            print('Importing errors for sequence {0:,.0f}...'.format(i))\n",
    "    this_seq_error_df = pandas.DataFrame()\n",
    "    this_seq_metadata_filename = '/home/idies/workspace/raddick_acs_data/metadata/Seq{0:.0f}.xls'.format(i)\n",
    "    this_seq_metadata_in_cols_df = pandas.read_excel(this_seq_metadata_filename, header=None, encoding='utf-8')\n",
    "    this_seq_metadata_in_cols_df = this_seq_metadata_in_cols_df.dropna(axis=1)\n",
    "    \n",
    "    if (i == 1):\n",
    "        this_seq_metadata_in_cols_df.columns = ['FILEID','FILETYPE','STUSAB','CHARITER','SEQUENCE','LOGRECNO','B00001_001_UW','B00001_002_UW']\n",
    "    else:\n",
    "        this_seq_metadata_in_cols_df.columns = this_seq_metadata_in_cols_df.loc[0]\n",
    "\n",
    "    this_seq_metadata_df = this_seq_metadata_in_cols_df.T\n",
    "    this_seq_metadata_df.columns = ['variable', 'description']\n",
    "    if (i == 1):\n",
    "        this_seq_metadata_df['variable'] = this_seq_metadata_in_cols_df.columns\n",
    "        this_seq_metadata_df['sequence_number'] = [0,0,0,0,0,0,1,1] \n",
    "    else:\n",
    "        this_seq_metadata_df['sequence_number'] = i\n",
    "    \n",
    "    for onestate in states:\n",
    "        statefilename = '/home/idies/workspace/raddick_acs_data/data/seq{0:.0f}/m20161{1:s}{2:04d}000.txt'.format(i,onestate,i)\n",
    "        onestate_df = pandas.read_csv(statefilename, header=None, sep=',', encoding='utf-8')\n",
    "        this_seq_error_df = this_seq_error_df.append(onestate_df)\n",
    "        \n",
    "    this_seq_error_df.columns = this_seq_metadata_in_cols_df.columns\n",
    "    \n",
    "    this_seq_error_df = this_seq_error_df.drop(['SEQUENCE'], axis=1)\n",
    "    if (i >= 2):\n",
    "        this_seq_metadata_df = this_seq_metadata_df.drop(['FILEID','FILETYPE','STUSAB', 'SEQUENCE', 'CHARITER','LOGRECNO'], axis=0)\n",
    "        this_seq_error_df = this_seq_error_df.drop(['FILEID','FILETYPE','STUSAB', 'CHARITER', 'LOGRECNO'], axis=1)\n",
    "\n",
    "#    if (debug >= 2):\n",
    "#        print('Merging datasets...')\n",
    "    metadata_df = pandas.concat((metadata_df, this_seq_metadata_df), axis=0)\n",
    "    error_df = pandas.concat((error_df, this_seq_error_df), axis=1)\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Creating pseudo geoid...')\n",
    "error_df['PSEUDO_GEOID'] = error_df['STUSAB'].str.upper() + error_df['LOGRECNO'].apply(lambda x: '{0:07d}'.format(x))\n",
    "\n",
    "#metadata_df.loc['PSEUDO_GEOID'] = ['PSEUDO_GEOID', 'Temporary ID constructed from the STUSAB and the 7-digit zero-padded LOGRECNO to use to look up the geoid later.', 0]\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Indexing...')\n",
    "error_df = error_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Reading geography file...')\n",
    "geoid_df = pandas.read_excel('metadata/geoid.xlsx', encoding='utf-8')\n",
    "geoid_df = geoid_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Merging geography with data...')\n",
    "error_df = error_df.join(geoid_df[['GEOID','NAME']])\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Resetting index...')\n",
    "#metadata_df = metadata_df.set_index('GEOID')\n",
    "\n",
    "metadata_df.loc['GEOID'] = ['GEOID', 'Geography identifier (also functions as index of data tables)', 0]\n",
    "metadata_df.loc['NAME'] = ['NAME', 'Name of geography region', 0]\n",
    "\n",
    "error_df = error_df.set_index('GEOID', drop=False)\n",
    "error_df.index.name = ''\n",
    "\n",
    "#metadata_df = metadata_df.set_index('variable', drop=False)\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing margins of error file...')\n",
    "data_df.to_csv('/home/idies/workspace/raddick_acs_data/error_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Done!')\n",
    "    \n",
    "    \n",
    "geo_df = pandas.DataFrame()\n",
    "geo_metadata_df = pandas.DataFrame()\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Importing geography data...')\n",
    "\n",
    "geo_metadata_filename = '/home/idies/workspace/raddick_acs_data/metadata/2016_SFGeoFileTemplate.xls'\n",
    "geo_metadata_df = pandas.read_excel(geo_metadata_filename, header=None, encoding='utf-8')\n",
    "geo_metadata_df = geo_metadata_df.dropna(axis=1)\n",
    "geo_metadata_df.columns = geo_metadata_df.loc[0]\n",
    "geo_metadata_df = geo_metadata_df.drop(0, axis=0)\n",
    "geo_metadata_df.index = ['description']\n",
    "\n",
    "for onestate in states:\n",
    "    statefilename = 'geography/g20161{0:}.csv'.format(onestate)\n",
    "    if (debug >= 2):\n",
    "        print(statefilename)\n",
    "    onestate_df = pandas.read_csv(statefilename, header=None, encoding='utf-8')\n",
    "    geo_df = geo_df.append(onestate_df)\n",
    "\n",
    "geo_df.columns = geo_metadata_df.columns\n",
    "geo_df = geo_df.set_index('GEOID', drop=False)\n",
    "geo_df.index.name = ''\n",
    "\n",
    "geo_metadata_df = geo_metadata_df.T\n",
    "geo_metadata_df = geo_metadata_df.reset_index()\n",
    "geo_metadata_df.columns = ['variable', 'description']\n",
    "geo_metadata_df = geo_metadata_df.set_index('variable', drop=False)\n",
    "geo_metadata_df.index.name = ''\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing geography variables file...')\n",
    "geo_metadata_df.to_csv('/home/idies/workspace/raddick_acs_data/geo_variables_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing geography file...')\n",
    "geo_df.to_csv('/home/idies/workspace/raddick_acs_data/geo_acs2016.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# reorder columns\n",
    "#new_column_list = []\n",
    "#new_column_list.append(geo_metadata_df.columns[len(geo_metadata_df.columns)-5])\n",
    "#for i in range(0,len(geo_metadata_df.columns)-5):\n",
    "#    new_column_list.append(geo_metadata_df.columns[i])\n",
    "#for j in range(len(geo_metadata_df.columns)-4, len(geo_metadata_df.columns)):\n",
    "#    new_column_list.append(geo_metadata_df.columns[j])\n",
    "#geo_metadata_df.columns = new_column_list\n",
    "\n",
    "#new_column_list = []\n",
    "#new_column_list.append(geo_df.columns[len(geo_df.columns)-5])\n",
    "#for i in range(0,len(geo_df.columns)-5):\n",
    "#    new_column_list.append(geo_df.columns[i])\n",
    "#for j in range(len(geo_df.columns)-4, len(geo_df.columns)):\n",
    "#    new_column_list.append(geo_df.columns[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print('Females under age 5 in Baltimore County: {0:,.0f} with margin of error {1:,.0f}'.format(data_df['B01001_027'].loc['05000US24510'], error_df['B01001_027'].loc['05000US24510']))\n",
    "#data_df['B01001_027'].loc['05000US24510']\n",
    "#error_df['B01001_027'].loc['05000US24510']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
