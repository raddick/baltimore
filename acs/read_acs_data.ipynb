{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing data for sequence 1...\n",
      "Importing data for sequence 2...\n",
      "Importing data for sequence 3...\n",
      "Importing data for sequence 4...\n",
      "Importing data for sequence 5...\n",
      "Importing data for sequence 6...\n",
      "Importing data for sequence 139...\n",
      "Importing data for sequence 140...\n",
      "Importing data for sequence 141...\n",
      "Importing data for sequence 142...\n",
      "Importing data for sequence 143...\n",
      "Importing data for sequence 144...\n",
      "Importing data for sequence 145...\n",
      "Importing data for sequence 146...\n",
      "Importing data for sequence 147...\n",
      "Importing data for sequence 148...\n",
      "Importing data for sequence 149...\n",
      "Importing data for sequence 150...\n",
      "Writing variables file...\n",
      "Writing data (estimates) file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "debug = 1\n",
    "import numpy as np\n",
    "import pandas\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "states = ['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc']\n",
    "states += ['de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in']\n",
    "states += ['ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn']\n",
    "states += ['mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj']\n",
    "states += ['nh', 'nj', 'nm', 'nv', 'ny', 'oh', 'ok', 'or']\n",
    "states += ['pa', 'pr', 'ri', 'sc', 'sd', 'tn', 'tx', 'us']\n",
    "states += ['ut' ,'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
    "\n",
    "data_df = pandas.DataFrame()\n",
    "metadata_df = pandas.DataFrame()\n",
    "\n",
    "# 1-6, 139-150\n",
    "want_sequences = []\n",
    "for i in range(1,7):\n",
    "    want_sequences.append(i)\n",
    "for i in range(139,151):\n",
    "    want_sequences.append(i)\n",
    "\n",
    "#print(want_sequences)\n",
    "\n",
    "#for i in range(1,167):\n",
    "for i in want_sequences:\n",
    "    if (debug >= 1):\n",
    "#        if (np.mod(i, 10) == 0):\n",
    "        print('Importing data for sequence {0:,.0f}...'.format(i))\n",
    "    this_seq_data_df = pandas.DataFrame()\n",
    "    this_seq_metadata_filename = '/home/idies/workspace/raddick_acs_data/metadata/Seq{0:.0f}.xls'.format(i)\n",
    "    this_seq_metadata_in_cols_df = pandas.read_excel(this_seq_metadata_filename, header=None, encoding='utf-8')\n",
    "    this_seq_metadata_in_cols_df = this_seq_metadata_in_cols_df.dropna(axis=1)\n",
    "    \n",
    "    if (i == 1):\n",
    "        this_seq_metadata_in_cols_df.columns = ['FILEID','FILETYPE','STUSAB','CHARITER','SEQUENCE','LOGRECNO','B00001_001_UW','B00001_002_UW']\n",
    "    else:\n",
    "        this_seq_metadata_in_cols_df.columns = this_seq_metadata_in_cols_df.loc[0]\n",
    "\n",
    "    this_seq_metadata_df = this_seq_metadata_in_cols_df.T\n",
    "    this_seq_metadata_df.columns = ['variable', 'description']\n",
    "    if (i == 1):\n",
    "        this_seq_metadata_df['variable'] = this_seq_metadata_in_cols_df.columns\n",
    "        this_seq_metadata_df['sequence_number'] = [0,0,0,0,0,0,1,1] \n",
    "    else:\n",
    "        this_seq_metadata_df['sequence_number'] = i\n",
    "    \n",
    "    for onestate in states:\n",
    "        statefilename = '/home/idies/workspace/raddick_acs_data/data/seq{0:.0f}/e20161{1:s}{2:04d}000.txt'.format(i,onestate,i)\n",
    "        onestate_df = pandas.read_csv(statefilename, header=None, sep=',', encoding='utf-8')\n",
    "        this_seq_data_df = this_seq_data_df.append(onestate_df)\n",
    "        \n",
    "    this_seq_data_df.columns = this_seq_metadata_in_cols_df.columns\n",
    "    \n",
    "    this_seq_data_df = this_seq_data_df.drop(['SEQUENCE'], axis=1)\n",
    "    if (i >= 2):\n",
    "        this_seq_metadata_df = this_seq_metadata_df.drop(['FILEID','FILETYPE','STUSAB', 'SEQUENCE', 'CHARITER','LOGRECNO'], axis=0)\n",
    "        this_seq_data_df = this_seq_data_df.drop(['FILEID','FILETYPE','STUSAB', 'CHARITER', 'LOGRECNO'], axis=1)\n",
    "\n",
    "#    if (debug >= 2):\n",
    "#        print('Merging datasets...')\n",
    "    metadata_df = pandas.concat((metadata_df, this_seq_metadata_df), axis=0)\n",
    "    data_df = pandas.concat((data_df, this_seq_data_df), axis=1)\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Creating pseudo geoid...')\n",
    "data_df['PSEUDO_GEOID'] = data_df['STUSAB'].str.upper() + data_df['LOGRECNO'].apply(lambda x: '{0:07d}'.format(x))\n",
    "\n",
    "#metadata_df.loc['PSEUDO_GEOID'] = ['PSEUDO_GEOID', 'Temporary ID constructed from the STUSAB and the 7-digit zero-padded LOGRECNO to use to look up the geoid later.', 0]\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Indexing...')\n",
    "data_df = data_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Reading geography file...')\n",
    "geoid_df = pandas.read_excel('metadata/geoid.xlsx', encoding='utf-8')\n",
    "geoid_df = geoid_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Merging geography with data...')\n",
    "data_df = data_df.join(geoid_df[['GEOID','NAME']])\n",
    "#data_df = data_df.rename(columns={'NAME': 'GEO_NAME'})\n",
    "\n",
    "#metadata_df['GEOID'] = 'Geography identifier'\n",
    "#metadata_df['NAME'] = 'Name of geography unit'\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Resetting index...')\n",
    "#metadata_df = metadata_df.set_index('GEOID')\n",
    "\n",
    "metadata_df.loc['GEOID'] = ['GEOID', 'Geography identifier (also functions as index of data tables)', 0]\n",
    "metadata_df.loc['NAME'] = ['NAME', 'Name of geography region', 0]\n",
    "\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Rearranging columns')\n",
    "cols = data_df.columns.tolist()\n",
    "\n",
    "data_df = data_df.set_index('GEOID', drop=False)\n",
    "data_df.index.name = ''\n",
    "\n",
    "cols = cols[-2:] + cols[:-2]\n",
    "data_df = data_df[cols]\n",
    "\n",
    "metadata_rows = cols\n",
    "#metadata_rows = ['GEOID'] + cols\n",
    "metadata_df = metadata_df.reindex(metadata_rows)\n",
    "\n",
    "#metadata_df = metadata_df.set_index('variable', drop=False)\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing variables file...')\n",
    "metadata_df.to_csv('/home/idies/workspace/raddick_acs_data/variables_clara.csv', encoding='utf-8')\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing data (estimates) file...')\n",
    "data_df.to_csv('/home/idies/workspace/raddick_acs_data/data_acs2016_clara.csv', encoding='utf-8')\n",
    "\n",
    "print('Done!')\n",
    "#cols\n",
    "#data_df.sample(1)\n",
    "#metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "debug = 1\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "states = ['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc']\n",
    "states += ['de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in']\n",
    "states += ['ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn']\n",
    "states += ['mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj']\n",
    "states += ['nh', 'nj', 'nm', 'nv', 'ny', 'oh', 'ok', 'or']\n",
    "states += ['pa', 'pr', 'ri', 'sc', 'sd', 'tn', 'tx', 'us']\n",
    "states += ['ut' ,'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
    "\n",
    "# 1-6, 139-150\n",
    "want_sequences = []\n",
    "for i in range(1,7):\n",
    "    want_sequences.append(i)\n",
    "for i in range(139,151):\n",
    "    want_sequences.append(i)\n",
    "\n",
    "error_df = pandas.DataFrame()\n",
    "metadata_df = pandas.DataFrame()\n",
    "\n",
    "#for i in range(1,167):\n",
    "for i in want_sequences:\n",
    "    if (debug >= 1):\n",
    "        print('Importing data for sequence {0:,.0f}...'.format(i))\n",
    "    this_seq_error_df = pandas.DataFrame()\n",
    "    this_seq_metadata_filename = '/home/idies/workspace/raddick_acs_data/metadata/Seq{0:.0f}.xls'.format(i)\n",
    "    this_seq_metadata_in_cols_df = pandas.read_excel(this_seq_metadata_filename, header=None, encoding='utf-8')\n",
    "    this_seq_metadata_in_cols_df = this_seq_metadata_in_cols_df.dropna(axis=1)\n",
    "    \n",
    "    if (i == 1):\n",
    "        this_seq_metadata_in_cols_df.columns = ['FILEID','FILETYPE','STUSAB','CHARITER','SEQUENCE','LOGRECNO','B00001_001_UW','B00001_002_UW']\n",
    "    else:\n",
    "        this_seq_metadata_in_cols_df.columns = this_seq_metadata_in_cols_df.loc[0]\n",
    "\n",
    "    this_seq_metadata_df = this_seq_metadata_in_cols_df.T\n",
    "    this_seq_metadata_df.columns = ['variable', 'description']\n",
    "    if (i == 1):\n",
    "        this_seq_metadata_df['variable'] = this_seq_metadata_in_cols_df.columns\n",
    "        this_seq_metadata_df['sequence_number'] = [0,0,0,0,0,0,1,1] \n",
    "    else:\n",
    "        this_seq_metadata_df['sequence_number'] = i\n",
    "    \n",
    "    for onestate in states:\n",
    "        statefilename = '/home/idies/workspace/raddick_acs_data/data/seq{0:.0f}/m20161{1:s}{2:04d}000.txt'.format(i,onestate,i)\n",
    "        onestate_df = pandas.read_csv(statefilename, header=None, sep=',', encoding='utf-8')\n",
    "        this_seq_error_df = this_seq_error_df.append(onestate_df)\n",
    "        \n",
    "    this_seq_error_df.columns = this_seq_metadata_in_cols_df.columns\n",
    "    \n",
    "    this_seq_error_df = this_seq_error_df.drop(['SEQUENCE'], axis=1)\n",
    "    if (i >= 2):\n",
    "        this_seq_metadata_df = this_seq_metadata_df.drop(['FILEID','FILETYPE','STUSAB', 'SEQUENCE', 'CHARITER','LOGRECNO'], axis=0)\n",
    "        this_seq_error_df = this_seq_error_df.drop(['FILEID','FILETYPE','STUSAB', 'CHARITER', 'LOGRECNO'], axis=1)\n",
    "\n",
    "#    if (debug >= 2):\n",
    "#        print('Merging datasets...')\n",
    "    metadata_df = pandas.concat((metadata_df, this_seq_metadata_df), axis=0)\n",
    "    error_df = pandas.concat((error_df, this_seq_error_df), axis=1)\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Creating pseudo geoid...')\n",
    "error_df['PSEUDO_GEOID'] = error_df['STUSAB'].str.upper() + error_df['LOGRECNO'].apply(lambda x: '{0:07d}'.format(x))\n",
    "\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Indexing...')\n",
    "error_df = error_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Reading geography file...')\n",
    "geoid_df = pandas.read_excel('metadata/geoid.xlsx', encoding='utf-8')\n",
    "geoid_df = geoid_df.set_index('PSEUDO_GEOID')\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Merging geography with data...')\n",
    "error_df = error_df.join(geoid_df[['GEOID','NAME']])\n",
    "#data_df = data_df.rename(columns={'NAME': 'GEO_NAME'})\n",
    "\n",
    "#metadata_df['GEOID'] = 'Geography identifier'\n",
    "#metadata_df['NAME'] = 'Name of geography unit'\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Resetting index...')\n",
    "#metadata_df = metadata_df.set_index('GEOID')\n",
    "\n",
    "metadata_df.loc['GEOID'] = ['GEOID', 'Geography identifier (also functions as index of data tables)', 0]\n",
    "metadata_df.loc['NAME'] = ['NAME', 'Name of geography region', 0]\n",
    "\n",
    "\n",
    "if (debug >= 2):\n",
    "    print('Rearranging columns')\n",
    "cols = error_df.columns.tolist()\n",
    "\n",
    "error_df = error_df.set_index('GEOID', drop=False)\n",
    "\n",
    "cols = cols[-2:] + cols[:-2]\n",
    "error_df = error_df[cols]\n",
    "\n",
    "metadata_rows = cols\n",
    "#metadata_rows = ['GEOID'] + cols\n",
    "metadata_df = metadata_df.reindex(metadata_rows)\n",
    "\n",
    "#metadata_df = metadata_df.set_index('variable', drop=False)\n",
    "\n",
    "#if (debug >= 1):\n",
    "#    print('Writing variables file...')\n",
    "#metadata_df.to_csv('/home/idies/workspace/raddick_acs_data/variables_acs2016_1_2.csv', encoding='utf-8')\n",
    "error_df.index.name = ''\n",
    "\n",
    "\n",
    "if (debug >= 1):\n",
    "    print('Writing margins of error file...')\n",
    "error_df.to_csv('/home/idies/workspace/raddick_acs_data/error_acs2016_clara.csv', encoding='utf-8')\n",
    "\n",
    "print('Done!')\n",
    "#cols\n",
    "#error_df.sample(1)\n",
    "#metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing geography data...\n",
      "Writing geography variables file...\n",
      "Writing geography file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "debug = 1\n",
    "import numpy as np\n",
    "import pandas\n",
    "\n",
    "\n",
    "states = ['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc']\n",
    "states += ['de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in']\n",
    "states += ['ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn']\n",
    "states += ['mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj']\n",
    "states += ['nh', 'nj', 'nm', 'nv', 'ny', 'oh', 'ok', 'or']\n",
    "states += ['pa', 'pr', 'ri', 'sc', 'sd', 'tn', 'tx', 'us']\n",
    "states += ['ut' ,'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
    "\n",
    "geo_df = pandas.DataFrame()\n",
    "geo_metadata_df = pandas.DataFrame()\n",
    "\n",
    "print('Importing geography data...')\n",
    "\n",
    "geo_metadata_filename = 'metadata/2016_SFGeoFileTemplate.xls'\n",
    "geo_metadata_df = pandas.read_excel(geo_metadata_filename, header=None, encoding='utf-8')\n",
    "geo_metadata_df = geo_metadata_df.dropna(axis=1)\n",
    "geo_metadata_df.columns = geo_metadata_df.loc[0]\n",
    "geo_metadata_df = geo_metadata_df.drop(0, axis=0)\n",
    "geo_metadata_df.index = ['description']\n",
    "\n",
    "for onestate in states:\n",
    "    statefilename = 'geography/g20161{0:}.csv'.format(onestate)\n",
    "    if (debug >= 2):\n",
    "        print(statefilename)\n",
    "    onestate_df = pandas.read_csv(statefilename, header=None, encoding='utf-8')\n",
    "    geo_df = geo_df.append(onestate_df)\n",
    "\n",
    "geo_df.columns = geo_metadata_df.columns\n",
    "geo_df = geo_df.set_index('GEOID', drop=False)\n",
    "geo_df.index.name = ''\n",
    "\n",
    "geo_metadata_df = geo_metadata_df.T\n",
    "geo_metadata_df = geo_metadata_df.reset_index()\n",
    "geo_metadata_df.columns = ['variable', 'description']\n",
    "geo_metadata_df = geo_metadata_df.set_index('variable', drop=False)\n",
    "geo_metadata_df.index.name = ''\n",
    "\n",
    "#geo_df = geo_df[columns=new_column_list]\n",
    "\n",
    "#new_geo_df.tail(1)\n",
    "#geo_metadata_df\n",
    "\n",
    "#newcols\n",
    "#df = df[cols]\n",
    "print('Writing geography variables file...')\n",
    "geo_metadata_df.to_csv('/home/idies/workspace/raddick_acs_data/geo_variables_acs2016_clara.csv', encoding='utf-8')\n",
    "\n",
    "print('Writing geography file...')\n",
    "geo_df.to_csv('/home/idies/workspace/raddick_acs_data/geo_acs2016_clara.csv', encoding='utf-8')\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# reorder columns\n",
    "new_column_list = []\n",
    "new_column_list.append(geo_metadata_df.columns[len(geo_metadata_df.columns)-5])\n",
    "for i in range(0,len(geo_metadata_df.columns)-5):\n",
    "    new_column_list.append(geo_metadata_df.columns[i])\n",
    "for j in range(len(geo_metadata_df.columns)-4, len(geo_metadata_df.columns)):\n",
    "    new_column_list.append(geo_metadata_df.columns[j])\n",
    "geo_metadata_df.columns = new_column_list\n",
    "\n",
    "new_column_list = []\n",
    "new_column_list.append(geo_df.columns[len(geo_df.columns)-5])\n",
    "for i in range(0,len(geo_df.columns)-5):\n",
    "    new_column_list.append(geo_df.columns[i])\n",
    "for j in range(len(geo_df.columns)-4, len(geo_df.columns)):\n",
    "    new_column_list.append(geo_df.columns[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "varlist = []\n",
    "string1 = 'Baltimore'\n",
    "#string2 = 'Male'\n",
    "#string3 = ' '\n",
    "\n",
    "#string1 = 'TRAVEL TIME\n",
    "#string2 = '10 to 14 Minutes\n",
    "#string3 = 'bus'\n",
    "#string1 = 'MALE'\n",
    "string2 = ' '\n",
    "string3 = ' '\n",
    "#string2 = 'all'\n",
    "#string3 = ''\n",
    "\n",
    "geo_df['NAME'][geo_df['NAME'].apply(lambda x: (string1 in x) & (string2 in x) & (string3 in x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Females under age 5 in Baltimore County: {0:,.0f} with margin of error {1:,.0f}'.format(data_df['B01001_027'].loc['05000US24510'], error_df['B01001_027'].loc['05000US24510']))\n",
    "#data_df['B01001_027'].loc['05000US24510']\n",
    "#error_df['B01001_027'].loc['05000US24510']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
