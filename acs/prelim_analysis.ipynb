{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from IPython.display import display, HTML\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "\n",
    "print('Reading metadata...')\n",
    "metadata_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/variables_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "geo_metadata_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geo_variables_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Reading geography...')\n",
    "geo_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geo_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Reading data (estimates)...')\n",
    "data_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/data_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Reading margins of error...')\n",
    "error_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/error_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Calculating geography sumary levels...')\n",
    "data_df['SUMLEVEL'] = data_df['GEOID'].apply(lambda x: int(x[0:3]))\n",
    "\n",
    "print('Documenting geography summary levels...')\n",
    "sumlevel_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geography/geo_summary_levels.csv', encoding='utf-8')\n",
    "sumlevel_df = sumlevel_df.set_index('SUMLEVEL', drop=False)\n",
    "\n",
    "print('Documenting state codes')\n",
    "geo_df[['STATE','STUSAB']].dropna().drop_duplicates().sort_values('STATE').to_csv('/home/idies/workspace/raddick_acs_data/geography/statecodes.csv', encoding='utf-8', index=False)\n",
    "statecodes_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geography/statecodes.csv', encoding='utf-8')\n",
    "statecodes_df['STATE'] = statecodes_df['STATE'].astype('int')\n",
    "statecodes_df = statecodes_df.set_index('STATE', drop=False)\n",
    "\n",
    "print('\\n')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#metadata_df\n",
    "#metadata_df[metadata_df['sequence_number'] == 150]\n",
    "#metadata_df\n",
    "#B26001_001\n",
    "#GROUP QUARTERS POPULATION for Population In Group Quarters% Total\n",
    "\n",
    "#string1 = 'Baltimore'\n",
    "#string2 = ''\n",
    "#string3 = ''\n",
    "\n",
    "#geovarlist = metadata_df['variable'][metadata_df['description'].apply(lambda x: (string1 in x) & (string2 in x) & (string3 in x))].values.tolist()\n",
    "#geo_df[geo_df['NAME'].apply(lambda x: (string1 in x))]\n",
    "\n",
    "#print('{0:}'.format(geo_df['NAME'].loc['05000US24510']))\n",
    "#print('{0:} {1:,.0f}'.format(metadata_df['description'].loc['B26001_001'], data_df['B26001_001'].loc['05000US24510']))\n",
    "\n",
    "#data_df['B26001_001'].loc['05000US24510']\n",
    "#data_df      \n",
    "#05000US24510\n",
    "#data_df['B26001_001'].sample(1)\n",
    "\n",
    "geolist = geo_df['GEOID'].sample(3).values.tolist()\n",
    "#geolist.append('afwwfe')\n",
    "    \n",
    "thelist = ['NAME','B01001_001', 'B26001_001']\n",
    "#thelist.append('xxx')\n",
    "#thelist  = []\n",
    "#ourdata_df = get_data(data_df, thelist, geolist)\n",
    "#ourdata_df\n",
    "\n",
    "phrases = []\n",
    "phrases.append('Total Population')\n",
    "phrases.append('Female')\n",
    "#phrases.append('AGE')\n",
    "#phrases.append('Under 5')\n",
    "#phrases.append('Male')\n",
    "\n",
    "thegeolist = find_geography(data_df, 9)\n",
    "#thesevars = find_variables4(metadata_df, phrases)\n",
    "#find_variables(metadata_df, phrases)\n",
    "#metadata_df[metadata_df['variable'].apply(lambda x: x in thesevars)]\n",
    "#print(thesevars)\n",
    "#thegeo.groupby('SUMLEVEL').size()\n",
    "ourdata_df = get_data(data_df, thelist, thegeolist)\n",
    "ourdata_df\n",
    "#print(thegeolist)\n",
    "#sumlevel_df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def find_geography(ddf, wantlevel):\n",
    "    gdf = []\n",
    "    gdf = ddf['GEOID'][ddf['SUMLEVEL'] == wantlevel].values.tolist()\n",
    "    if (len(ddf['GEOID'][ddf['SUMLEVEL'] == wantlevel]) == 0):\n",
    "        showme = '<p><b>WARNING:</b> specified geography level ({0:.0f}) does not exist.<br />'.format(wantlevel)\n",
    "        showme += 'The table below shows possible values.</p>'\n",
    "        display(HTML(showme))\n",
    "        \n",
    "        helpshow_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geography/geo_summary_levels.csv')\n",
    "        helpshow_df = helpshow_df.set_index('SUMLEVEL')\n",
    "        #print(helpshow_df['description'])\n",
    "        showme = '<table><tr><th>SUMLEVEL</th><th>Description</th></tr>'\n",
    "        for slvl, row in helpshow_df.iterrows():\n",
    "#            print(str(slvl))\n",
    "            showme += '<tr><td>'+str(slvl)+'</td><td>'+str(row['description'])+'</td></tr>'\n",
    "        showme += '</table>'\n",
    "#        print(showme)\n",
    "        display(HTML(showme))\n",
    "    else:\n",
    "        gdf = ddf['GEOID'][ddf['SUMLEVEL'] == wantlevel].values.tolist()\n",
    "    return gdf\n",
    "    \n",
    "def find_variables4(mdf, tofindlist):\n",
    "    # NEED TO REWRITE TO USE REGEX INSTEAD, because now only \"Male\" returns men; \"male\" returns women b/c feMALE\n",
    "    varlist = []\n",
    "    if (len(tofindlist) == 0):\n",
    "        print('CAUTION: No search phrases specified, returning every variable!')\n",
    "    if (len(tofindlist) > 4):\n",
    "        print('ERROR: list contains more than four search phrases, searching for only the first three')\n",
    "    try:\n",
    "        string1 = tofindlist[0]\n",
    "    except IndexError:\n",
    "        string1 = ''\n",
    "    try:\n",
    "        string2 = tofindlist[1]\n",
    "    except IndexError:\n",
    "        string2 = ''\n",
    "    try:\n",
    "        string3 = tofindlist[2]\n",
    "    except IndexError:\n",
    "        string3 = ''\n",
    "    try:\n",
    "        string4 = tofindlist[3]\n",
    "    except IndexError:\n",
    "        string4 = ''\n",
    "            \n",
    "    varlist = mdf['variable'][mdf['description'].apply(lambda x: (string1 in x) & (string2 in x) & (string3 in x) & (string4 in x))].values.tolist()\n",
    "    return varlist\n",
    "\n",
    "def get_data(df, varlist, geolist):\n",
    "    y_df = get_geography(df, geolist)\n",
    "    rdf = get_columns(y_df, varlist)\n",
    "    return rdf\n",
    "\n",
    "def get_columns(df, varlist):\n",
    "    if (len(varlist) == 0):\n",
    "        print('CAUTION: No variables specified')\n",
    "    rdf = pandas.DataFrame()\n",
    "    if (len(df) > 0):\n",
    "        vars_that_exist = ['GEOID']\n",
    "        for thisvar in varlist:\n",
    "            if (thisvar in df.columns):\n",
    "                vars_that_exist.append(thisvar)\n",
    "            else:\n",
    "                print('Variable {0:} not found. Skipping.'.format(thisvar))\n",
    "\n",
    "        rdf = df[vars_that_exist]\n",
    "        rdf.index.name = ''\n",
    "    else:\n",
    "        print('CAUTION: No geopgraphies specified')\n",
    "    return rdf\n",
    "\n",
    "def get_geography(df, geolist):\n",
    "    rdf = pandas.DataFrame()\n",
    "    if (len(df) > 0):\n",
    "        for thisgeo in geolist:\n",
    "            try:\n",
    "                rdf = rdf.append(df.loc[thisgeo])\n",
    "            except:\n",
    "                print('Geography {0:} not found. Skipping.'.format(thisgeo))\n",
    "    else:\n",
    "        print('No variables specified')\n",
    "    return rdf\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sumlevel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#geo_df[geo_df['SUMLEVEL'] != 40].groupby('STATE').size()\n",
    "# US = 1 if this is data for the U.S., only for SUMLEVEL = 10\n",
    "# REGION from 1 to 4, only for SUMLEVEL = 20\n",
    "# DIVISION from 1 to 9, only for SUMLEVEL = 30\n",
    "# STATE from 1 (AL) to 72 (PR), but skips several values. But they map one-to-one with STUSAB, so we don't really need them.\n",
    "# COUNTY from 1 to 810, different for different states. Numbers mostly alphabetical list, but with skips (old names?)\n",
    "\n",
    "# PLACE has only 596 distinct values, they seem mostly random\n",
    "# CBSA is probably combined statistical area, seems mostly random\n",
    "\n",
    "#geo_df[['STATE','STUSAB','NAME']][geo_df['STATE'] == 3].sample(10)\n",
    "#geo_df.groupby('PLACE').size()\n",
    "geo_df[['SUMLEVEL','STUSAB','PLACE','NAME']][geo_df['SUMLEVEL'] == 170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_df['SUMLEVEL'] = data_df['GEOID'].apply(lambda x: int(x[0:3]))\n",
    "\n",
    "print('Estimated U.S. population: {0:,.0f}'.format(data_df['B01001_001'].loc['01000US']))\n",
    "\n",
    "print('For the four census regions: {0:,.0f}'.format(data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:7]) == '02000US'].sum()))\n",
    "print('\\n')\n",
    "print('Population by census region:')\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US1'], data_df['B01001_001'].loc['02000US1']))\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US2'], data_df['B01001_001'].loc['02000US2']))\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US3'], data_df['B01001_001'].loc['02000US3']))\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US4'], data_df['B01001_001'].loc['02000US4']))\n",
    "\n",
    "#print('Men: {0:,.0f} (error: {1:,.0f})'.format(data_df['B01001_002'].loc['01000US'], error_df['B01001_002'].loc['01000US']))\n",
    "#print('Women: {0:,.0f} (error: {1:,.0f})'.format(data_df['B01001_026'].loc['01000US'], error_df['B01001_026'].loc['01000US']))\n",
    "\n",
    "#print('Margin of error: {0:,.0f}'.format(error_df['B01001_001'].loc['01000US']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#data_df[data_df['SUMLEVEL'] == 40]\n",
    "\n",
    "display(HTML('<h2>Population by state</h2>'))\n",
    "\n",
    "statetable = '<table><tr><th>State</th><th>Population</th></tr>'\n",
    "for thisgeoid, thisrow in data_df[data_df['GEOID'].apply(lambda x: x[0:5]) == '04000'].iterrows():\n",
    "    statetable += '<tr>'\n",
    "    statetable += '<td>{0:}</td><td style=\"text-align:right;padding:5px\">{1:,.0f}</td>'.format(thisrow['NAME'], thisrow['B01001_001'])\n",
    "    statetable += '</tr>'\n",
    "statetable += '</table>'\n",
    "\n",
    "display(HTML(statetable))\n",
    "\n",
    "total_population = data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:5]) == '04000'].sum()\n",
    "\n",
    "display(HTML(('TOTAL of all 50 states: <b>{0:,.0f}</b> (not equal to national b/c military etc. is federal)'.format(total_population))))\n",
    "#print('For the four census regions: {0:,.0f}'.format(data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:7]) == '02000US'].sum()))\n",
    "#data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:7]) == '02000US']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#geo_df[['SUMLEVEL','STUSAB','COUNTY','NAME']][(geo_df['SUMLEVEL'] == 310) & (geo_df['STUSAB'] == 'MD')].sort_values('COUNTY')\n",
    "#geo_df[geo_df['SUMLEVEL'] == 310].groupby('CBSA').size().sort_values()\n",
    "geo_df.sample(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
