{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata...\n",
      "Reading geography...\n",
      "Reading data (estimates)...\n",
      "Reading margins of error...\n",
      "Calculating geography sumary levels...\n",
      "Documenting geography summary levels...\n",
      "Documenting state codes\n",
      "\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from IPython.display import display, HTML\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "\n",
    "print('Reading metadata...')\n",
    "metadata_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/variables_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "geo_metadata_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geo_variables_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Reading geography...')\n",
    "geo_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geo_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Reading data (estimates)...')\n",
    "data_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/data_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Reading margins of error...')\n",
    "error_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/error_acs2016_clara.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Calculating geography sumary levels...')\n",
    "data_df['SUMLEVEL'] = data_df['GEOID'].apply(lambda x: int(x[0:3]))\n",
    "\n",
    "print('Documenting geography summary levels...')\n",
    "sumlevel_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geography/geo_summary_levels.csv', encoding='utf-8')\n",
    "sumlevel_df = sumlevel_df.set_index('SUMLEVEL', drop=False)\n",
    "\n",
    "print('Documenting state codes')\n",
    "geo_df[['STATE','STUSAB']].dropna().drop_duplicates().sort_values('STATE').to_csv('/home/idies/workspace/raddick_acs_data/geography/statecodes.csv', encoding='utf-8', index=False)\n",
    "statecodes_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geography/statecodes.csv', encoding='utf-8')\n",
    "statecodes_df['STATE'] = statecodes_df['STATE'].astype('int')\n",
    "statecodes_df = statecodes_df.set_index('STATE', drop=False)\n",
    "\n",
    "print('\\n')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B01001_003', 'B01001_027']\n",
      "Finding matching geographies...\n",
      "[50]\n",
      "Retrieving data...\n",
      "Geography 05000US19103 not found. Skipping.\n",
      "Geography 05000US19113 not found. Skipping.\n",
      "Geography 05000US19193 not found. Skipping.\n",
      "Geography 05000US16001 not found. Skipping.\n"
     ]
    }
   ],
   "source": [
    "#### metadata_df\n",
    "#metadata_df[metadata_df['sequence_number'] == 150]\n",
    "#metadata_df\n",
    "#B26001_001\n",
    "#GROUP QUARTERS POPULATION for Population In Group Quarters% Total\n",
    "\n",
    "#string1 = 'Baltimore'\n",
    "#string2 = ''\n",
    "#string3 = ''\n",
    "\n",
    "#geovarlist = metadata_df['variable'][metadata_df['description'].apply(lambda x: (string1 in x) & (string2 in x) & (string3 in x))].values.tolist()\n",
    "#geo_df[geo_df['NAME'].apply(lambda x: (string1 in x))]\n",
    "\n",
    "#print('{0:}'.format(geo_df['NAME'].loc['05000US24510']))\n",
    "#print('{0:} {1:,.0f}'.format(metadata_df['description'].loc['B26001_001'], data_df['B26001_001'].loc['05000US24510']))\n",
    "\n",
    "#data_df['B26001_001'].loc['05000US24510']\n",
    "\n",
    "\n",
    "#data_df      \n",
    "#05000US24510\n",
    "#data_df['B26001_001'].sample(1)\n",
    "\n",
    "phrases = []\n",
    "phrases.append('Total Population')\n",
    "#phrases.append('Female')\n",
    "phrases.append('Under 5')\n",
    "#phrases.append('Male')\n",
    "\n",
    "thelist = find_variables4(metadata_df, phrases)\n",
    "print(thelist)\n",
    "geos = ['Baltimore']\n",
    "#wantlevels = [10, 160]\n",
    "#wantlevels = [160]\n",
    "wantlevels = [50]\n",
    "\n",
    "print('Finding matching geographies...')\n",
    "geolist = find_geography4(geo_df, geos, wantlevels)\n",
    "\n",
    "#thesevars = find_variables4(metadata_df, phrases)\n",
    "#find_variables(metadata_df, phrases)\n",
    "#metadata_df[metadata_df['variable'].apply(lambda x: x in thesevars)]\n",
    "#print(thesevars)\n",
    "#thegeo.groupby('SUMLEVEL').size()\n",
    "\n",
    "#thelist = []\n",
    "print('Retrieving data...')\n",
    "ourdata_df = get_data(data_df, thelist, geolist)\n",
    "#sumlevel_df['description']\n",
    "\n",
    "\n",
    "#us, state, county, {cdp/place}, msa, city, urbanarea, congress, puma, school}\n",
    "#us,10\n",
    "#state,40\n",
    "#county,50\n",
    "#cdp,160\n",
    "#msa,310\n",
    "#city,312\n",
    "#urbanarea,400\n",
    "#congress,500\n",
    "#school, {950,960,970}\n",
    "\n",
    "ourdata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def find_geography4(gdf, tofindlist, wantlevels = []):\n",
    "    print(wantlevels)\n",
    "    geosub_df = pandas.DataFrame()\n",
    "    geolist = []\n",
    "\n",
    "    if (len(tofindlist) == 0):\n",
    "        print('CAUTION: No geography search phrases specified, returning every geography!')\n",
    "    if (len(tofindlist) > 4):\n",
    "        print('ERROR: list contains more than four geography search phrases, searching for only the first three')\n",
    "    try:\n",
    "        string1 = tofindlist[0]\n",
    "    except IndexError:\n",
    "        string1 = ''\n",
    "    try:\n",
    "        string2 = tofindlist[1]\n",
    "    except IndexError:\n",
    "        string2 = ''\n",
    "    try:\n",
    "        string3 = tofindlist[2]\n",
    "    except IndexError:\n",
    "        string3 = ''\n",
    "    try:\n",
    "        string4 = tofindlist[3]\n",
    "    except IndexError:\n",
    "        string4 = ''\n",
    "    \n",
    "    # If wantlevels not specified, search through every level\n",
    "    if (len(wantlevels) == 0):\n",
    "        geosub_df = gdf\n",
    "    for thislevel in wantlevels: \n",
    "        if (not(np.isnan(thislevel))):\n",
    "            geosub_df = pandas.concat((geosub_df,gdf[gdf['SUMLEVEL'] == thislevel]))\n",
    "\n",
    "    found_df = geosub_df[geosub_df['NAME'].apply(lambda x: (string1 in x) | (string2 in x) | (string3 in x) | (string4 in x))]\n",
    "    geolist = found_df['GEOID'].values.tolist()\n",
    "\n",
    "    return geolist\n",
    "    \n",
    "def warn_geo_level():\n",
    "    \n",
    "    helpshow_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geography/geo_summary_levels.csv')\n",
    "    helpshow_df = helpshow_df.set_index('SUMLEVEL')\n",
    "\n",
    "    showme = '<table><tr><th>SUMLEVEL</th><th>Description</th><th>Count</th></tr>'\n",
    "    for slvl, row in helpshow_df.iterrows():\n",
    "        showme += '<tr><td>'+str(slvl)+'</td><td>'+str(row['description'])+'</td><td>'+str(row['acscount'])+'</td></tr>'\n",
    "    showme += '</table>'\n",
    "\n",
    "    return showme\n",
    "    \n",
    "def find_variables4(mdf, tofindlist):\n",
    "    # NEED TO REWRITE TO USE REGEX INSTEAD, because now only \"Male\" returns men; \"male\" returns women b/c feMALE\n",
    "    varlist = []\n",
    "    if (len(tofindlist) == 0):\n",
    "        print('CAUTION: No search phrases specified, returning every variable!')\n",
    "    if (len(tofindlist) > 4):\n",
    "        print('ERROR: list contains more than four search phrases, searching for only the first three')\n",
    "    try:\n",
    "        string1 = tofindlist[0]\n",
    "    except IndexError:\n",
    "        string1 = ''\n",
    "    try:\n",
    "        string2 = tofindlist[1]\n",
    "    except IndexError:\n",
    "        string2 = ''\n",
    "    try:\n",
    "        string3 = tofindlist[2]\n",
    "    except IndexError:\n",
    "        string3 = ''\n",
    "    try:\n",
    "        string4 = tofindlist[3]\n",
    "    except IndexError:\n",
    "        string4 = ''\n",
    "            \n",
    "    varlist = mdf['variable'][mdf['description'].apply(lambda x: (string1 in x) & (string2 in x) & (string3 in x) & (string4 in x))].values.tolist()\n",
    "    return varlist\n",
    "\n",
    "def get_data(df, varlist = [], geolist = []):\n",
    "\n",
    "    rdf = pandas.DataFrame()\n",
    "    \n",
    "    if (len(geolist) == 0):\n",
    "        print('Caution: No geographies specified, will return all geographies')\n",
    "        rdf = df\n",
    "    else:\n",
    "        for thisgeo in geolist:\n",
    "            try:\n",
    "                rdf = rdf.append(df.loc[thisgeo])\n",
    "            except:\n",
    "                print('Geography {0:} not found. Skipping.'.format(thisgeo))\n",
    "\n",
    "    if (len(varlist) == 0):\n",
    "        print('CAUTION: No variables specified, will return all variables')\n",
    "    else:\n",
    "        vars_that_exist = ['GEOID']\n",
    "        for thisvar in varlist:\n",
    "            if (thisvar in df.columns):\n",
    "                vars_that_exist.append(thisvar)\n",
    "            else:\n",
    "                print('Variable {0:} not found. Skipping.'.format(thisvar))\n",
    "        rdf = rdf[vars_that_exist]\n",
    "    rdf.index.name = ''\n",
    "\n",
    "    return rdf\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#sumlevel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#geo_df[geo_df['SUMLEVEL'] != 40].groupby('STATE').size()\n",
    "# US = 1 if this is data for the U.S., only for SUMLEVEL = 10\n",
    "# REGION from 1 to 4, only for SUMLEVEL = 20\n",
    "# DIVISION from 1 to 9, only for SUMLEVEL = 30\n",
    "# STATE from 1 (AL) to 72 (PR), but skips several values. But they map one-to-one with STUSAB, so we don't really need them.\n",
    "# COUNTY from 1 to 810, different for different states. Numbers mostly alphabetical list, but with skips (old names?)\n",
    "\n",
    "# PLACE has only 596 distinct values, they seem mostly random\n",
    "# CBSA is probably combined statistical area, seems mostly random\n",
    "\n",
    "#geo_df[['STATE','STUSAB','NAME']][geo_df['STATE'] == 3].sample(10)\n",
    "#geo_df.groupby('PLACE').size()\n",
    "geo_df[['SUMLEVEL','STUSAB','PLACE','NAME']][geo_df['SUMLEVEL'] == 170]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_df['SUMLEVEL'] = data_df['GEOID'].apply(lambda x: int(x[0:3]))\n",
    "\n",
    "print('Estimated U.S. population: {0:,.0f}'.format(data_df['B01001_001'].loc['01000US']))\n",
    "\n",
    "print('For the four census regions: {0:,.0f}'.format(data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:7]) == '02000US'].sum()))\n",
    "print('\\n')\n",
    "print('Population by census region:')\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US1'], data_df['B01001_001'].loc['02000US1']))\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US2'], data_df['B01001_001'].loc['02000US2']))\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US3'], data_df['B01001_001'].loc['02000US3']))\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US4'], data_df['B01001_001'].loc['02000US4']))\n",
    "\n",
    "#print('Men: {0:,.0f} (error: {1:,.0f})'.format(data_df['B01001_002'].loc['01000US'], error_df['B01001_002'].loc['01000US']))\n",
    "#print('Women: {0:,.0f} (error: {1:,.0f})'.format(data_df['B01001_026'].loc['01000US'], error_df['B01001_026'].loc['01000US']))\n",
    "\n",
    "#print('Margin of error: {0:,.0f}'.format(error_df['B01001_001'].loc['01000US']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#data_df[data_df['SUMLEVEL'] == 40]\n",
    "\n",
    "display(HTML('<h2>Population by state</h2>'))\n",
    "\n",
    "statetable = '<table><tr><th>State</th><th>Population</th></tr>'\n",
    "for thisgeoid, thisrow in data_df[data_df['GEOID'].apply(lambda x: x[0:5]) == '04000'].iterrows():\n",
    "    statetable += '<tr>'\n",
    "    statetable += '<td>{0:}</td><td style=\"text-align:right;padding:5px\">{1:,.0f}</td>'.format(thisrow['NAME'], thisrow['B01001_001'])\n",
    "    statetable += '</tr>'\n",
    "statetable += '</table>'\n",
    "\n",
    "display(HTML(statetable))\n",
    "\n",
    "total_population = data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:5]) == '04000'].sum()\n",
    "\n",
    "display(HTML(('TOTAL of all 50 states: <b>{0:,.0f}</b> (not equal to national b/c military etc. is federal)'.format(total_population))))\n",
    "#print('For the four census regions: {0:,.0f}'.format(data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:7]) == '02000US'].sum()))\n",
    "#data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:7]) == '02000US']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#geo_df[['SUMLEVEL','STUSAB','COUNTY','NAME']][(geo_df['SUMLEVEL'] == 310) & (geo_df['STUSAB'] == 'MD')].sort_values('COUNTY')\n",
    "#geo_df[geo_df['SUMLEVEL'] == 310].groupby('CBSA').size().sort_values()\n",
    "geo_df.sample(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
