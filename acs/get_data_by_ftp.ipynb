{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In directory: /home/idies/workspace/raddick_acs_data/data2\n",
      "Preparing to read from https://www2.census.gov/programs-surveys/acs/summary_file/2016/data/1_year_entire_sf/All_Geographies.zip...\n",
      "Reading file...\n",
      "Writing zipfile...\n",
      "Reading zipfile...\n",
      "Extracting files...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import zipfile\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "local_dir = '/home/idies/workspace/raddick_acs_data/'\n",
    "data_dir = local_dir + 'data2/'\n",
    "\n",
    "if not (os.getcwd() == local_dir):\n",
    "    os.chdir(local_dir)\n",
    "if not (os.path.exists(data_dir)):\n",
    "    os.makedirs(data_dir)\n",
    "os.chdir(data_dir)\n",
    "print('In directory: '+os.getcwd())\n",
    "\n",
    "pageurl = 'https://www2.census.gov/programs-surveys/acs/summary_file/2016/data/1_year_entire_sf/All_Geographies.zip'\n",
    "\n",
    "print('Preparing to read from {0:}...'.format(pageurl))\n",
    "response = urllib.request.urlopen(pageurl)\n",
    "\n",
    "print('Reading file...')\n",
    "downloadedfile = response.read()\n",
    "\n",
    "print('Writing zipfile...')\n",
    "with open('All_Geographies.zip', 'wb') as f:\n",
    "    f.write(downloadedfile)\n",
    "\n",
    "print('Reading zipfile...')\n",
    "thezipfile = zipfile.ZipFile('All_Geographies.zip')\n",
    "\n",
    "print('Extracting files...')\n",
    "thezipfile.extractall()\n",
    "\n",
    "thezipfile.close()\n",
    "    \n",
    "#page = urllib.request.urlopen(pageurl).read()\n",
    "\n",
    "#soup = bs(page, \"html.parser\")\n",
    "\n",
    "#thetables = soup.find_all('table')\n",
    "\n",
    "#for thistable in thetables:\n",
    "#    therows = soup.find_all('tr')\n",
    "#    for thisrow in therows:\n",
    "#        thecols = soup.find_all('td')\n",
    "#        for thiscol in thecols:\n",
    "#            theselinks = thiscol.find_all('a')\n",
    "#            for thislink in theselinks:\n",
    "#                if (thislink['href'] == 'All_Geographies.zip'):\n",
    "#                    pprint(thislink['href'])\n",
    "\n",
    "\n",
    "#print('done')\n",
    "\n",
    "#ftp = FTP('ftp.fu-berlin.de') \n",
    "#ftp.login()\n",
    "#ftp.getwelcome()\n",
    "#ftp.cwd('pub/misc/movies/database/')\n",
    "#filenames = []\n",
    "#for filename in ftp.nlst():\n",
    "#    if ((filename == 'README') or (str(filename)[-3:] == '.gz')):\n",
    "#        filenames.append(filename)\n",
    "\n",
    "#print(str(len(filenames))+' files found.')\n",
    "\n",
    "#i = 1\n",
    "#for filename in filenames:\n",
    "#    local_filename = filename#os.path.join(data_dir, filename)\n",
    "#    file = open(local_filename, 'wb')\n",
    "#    print('Getting file '+str(i)+' of '+str(len(filenames))+': '+local_filename+'...')\n",
    "#    ftp.retrbinary('RETR '+ filename, file.write)\n",
    "#    file.close()\n",
    "#    i = i + 1\n",
    "#ftp.quit()\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
