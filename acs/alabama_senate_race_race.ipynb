{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade pip\n",
    "#!pip install numpy\n",
    "#!pip install pandas\n",
    "#!pip install xlrd\n",
    "#!pip install GEOS\n",
    "#!pip install GeobricksProj4ToEPSG\n",
    "#!conda install -c conda-forge cartopy --yes\n",
    "#!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from IPython.display import display, HTML\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "\n",
    "basedir = '/home/idies/workspace/raddick_census/'\n",
    "\n",
    "# category can be one of: demographics, ancestry, residence, transportation... \n",
    "#      household, income, employment, housing, qa\n",
    "\n",
    "category = 'demographics'\n",
    "\n",
    "vardir = basedir + 'variables/'\n",
    "geodir = basedir + 'geography/'\n",
    "datadir = basedir + 'data/'\n",
    "errordir = basedir + 'error/'\n",
    "\n",
    "print('Reading metadata...')\n",
    "metadata_df = pandas.read_csv(vardir+'variables_acs2016_{0:}.csv'.format(category), low_memory=False, index_col=0, encoding='utf-8')\n",
    "metadata_df.index.name = ''\n",
    "metadata_df = metadata_df.rename(columns={'variable.1': 'variable'})\n",
    "\n",
    "geo_metadata_df = pandas.read_csv(geodir+'geo_variables_acs2016.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Reading geography...')\n",
    "geo_df = pandas.read_csv(geodir+'geo_acs2016.csv', low_memory=False, index_col=0, encoding='utf-8')\n",
    "geo_df = geo_df.set_index('GEOID', drop=False)\n",
    "\n",
    "print('Reading data (estimates)...')\n",
    "data_df = pandas.read_csv(datadir+'data_acs2016_{0:}.csv'.format(category), low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Reading margins of error...')\n",
    "error_df = pandas.read_csv(errordir+'error_acs2016_{0:}.csv'.format(category), low_memory=False, index_col=0, encoding='utf-8')\n",
    "\n",
    "print('Calculating geography sumary levels...')\n",
    "data_df['SUMLEVEL'] = data_df['GEOID'].apply(lambda x: int(x[0:3]))\n",
    "\n",
    "print('Documenting geography summary levels...')\n",
    "sumlevel_df = pandas.read_csv(geodir+'geo_summary_levels.csv', encoding='utf-8')\n",
    "sumlevel_df = sumlevel_df.set_index('SUMLEVEL', drop=False)\n",
    "\n",
    "print('Documenting state codes')\n",
    "geo_df[['STATE','STUSAB']].dropna().drop_duplicates().sort_values('STATE').to_csv(geodir+'statecodes.csv', encoding='utf-8', index=False)\n",
    "statecodes_df = pandas.read_csv(geodir+'statecodes.csv', encoding='utf-8')\n",
    "statecodes_df['STATE'] = statecodes_df['STATE'].astype('int')\n",
    "statecodes_df = statecodes_df.set_index('STATE', drop=False)\n",
    "\n",
    "print('\\n')\n",
    "print('Done!')\n",
    "#sumlevel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_geography4(gdf, tofindlist, wantlevels = []):\n",
    "    geosub_df = pandas.DataFrame()\n",
    "    geolist = []\n",
    "\n",
    "    if (len(tofindlist) == 0):\n",
    "        print('CAUTION: No geography search phrases specified, returning every geography!')\n",
    "    if (len(tofindlist) > 4):\n",
    "        print('ERROR: list contains more than four geography search phrases, searching for only the first three')\n",
    "    try:\n",
    "        string1 = tofindlist[0]\n",
    "    except IndexError:\n",
    "        string1 = ''\n",
    "    try:\n",
    "        string2 = tofindlist[1]\n",
    "    except IndexError:\n",
    "        string2 = ''\n",
    "    try:\n",
    "        string3 = tofindlist[2]\n",
    "    except IndexError:\n",
    "        string3 = ''\n",
    "    try:\n",
    "        string4 = tofindlist[3]\n",
    "    except IndexError:\n",
    "        string4 = ''\n",
    "    \n",
    "    # If wantlevels not specified, search through every level\n",
    "    if (len(wantlevels) == 0):\n",
    "        geosub_df = gdf\n",
    "    for thislevel in wantlevels: \n",
    "        if (not(np.isnan(thislevel))):\n",
    "            geosub_df = pandas.concat((geosub_df,gdf[gdf['SUMLEVEL'] == thislevel]))\n",
    "#            print(geosub_df.head(1))\n",
    "    found_df = geosub_df[geosub_df['NAME'].apply(lambda x: (string1 in x) & (string2 in x) & (string3 in x) & (string4 in x))]\n",
    "    geolist = found_df['GEOID'].values.tolist()\n",
    "\n",
    "    return geolist\n",
    "    \n",
    "def warn_geo_level():\n",
    "    \n",
    "    helpshow_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/geography/geo_summary_levels.csv')\n",
    "    helpshow_df = helpshow_df.set_index('SUMLEVEL')\n",
    "\n",
    "    showme = '<table><tr><th>SUMLEVEL</th><th>Description</th><th>Count</th></tr>'\n",
    "    for slvl, row in helpshow_df.iterrows():\n",
    "        showme += '<tr><td>'+str(slvl)+'</td><td>'+str(row['description'])+'</td><td>'+str(row['acscount'])+'</td></tr>'\n",
    "    showme += '</table>'\n",
    "\n",
    "    return showme\n",
    "    \n",
    "def find_variables4(mdf, tofindlist):\n",
    "    # NEED TO REWRITE TO USE REGEX INSTEAD, because now only \"Male\" returns men; \"male\" returns women b/c feMALE\n",
    "    varlist = []\n",
    "    if (len(tofindlist) == 0):\n",
    "        print('CAUTION: No search phrases specified, returning every variable!')\n",
    "    if (len(tofindlist) > 4):\n",
    "        print('ERROR: list contains more than four search phrases, searching for only the first three')\n",
    "    try:\n",
    "        string1 = tofindlist[0]\n",
    "    except IndexError:\n",
    "        string1 = ''\n",
    "    try:\n",
    "        string2 = tofindlist[1]\n",
    "    except IndexError:\n",
    "        string2 = ''\n",
    "    try:\n",
    "        string3 = tofindlist[2]\n",
    "    except IndexError:\n",
    "        string3 = ''\n",
    "    try:\n",
    "        string4 = tofindlist[3]\n",
    "    except IndexError:\n",
    "        string4 = ''\n",
    "            \n",
    "    varlist = mdf['variable'][mdf['description'].apply(lambda x: (string1 in x) & (string2 in x) & (string3 in x) & (string4 in x))].values.tolist()\n",
    "    return varlist\n",
    "\n",
    "def get_data(df, varlist = [], geolist = []):\n",
    "\n",
    "    rdf = pandas.DataFrame()\n",
    "    \n",
    "    if (len(geolist) == 0):\n",
    "        print('Caution: No geographies specified, will return all geographies')\n",
    "        rdf = df\n",
    "    else:\n",
    "        for thisgeo in geolist:\n",
    "            try:\n",
    "                rdf = rdf.append(df.loc[thisgeo])\n",
    "            except:\n",
    "                print('Geography {0:} not found. Skipping.'.format(thisgeo))\n",
    "\n",
    "    if (len(varlist) == 0):\n",
    "        print('CAUTION: No variables specified, will return all variables')\n",
    "    else:\n",
    "        vars_that_exist = ['GEOID']\n",
    "        for thisvar in varlist:\n",
    "            if (thisvar in df.columns):\n",
    "                vars_that_exist.append(thisvar)\n",
    "            else:\n",
    "                print('Variable {0:} not found. Skipping.'.format(thisvar))\n",
    "        rdf = rdf[vars_that_exist]\n",
    "    rdf.index.name = ''\n",
    "\n",
    "    return rdf\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = []\n",
    "phrases.append('Total Population')\n",
    "phrases.append('one race')\n",
    "phrases.append('White alone')\n",
    "thelist = find_variables4(metadata_df, phrases)\n",
    "for x in thelist:\n",
    "    print(x, metadata_df['description'].loc[x])\n",
    "print('\\n')\n",
    "\n",
    "#B01001_001 SEX BY AGE for Total Population% Total:\n",
    "#B02001_002 RACE for Total Population% Black or African American alone\n",
    "#B02003_003 DETAILED RACE for Total Population% Population of one race:% White alone\n",
    "thelist = ['B01001_001', 'B02001_002', 'B02001_003']\n",
    "print(thelist)\n",
    "#sumlevel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geos = []\n",
    "#wantlevels = [40]\n",
    "thislevel = 500\n",
    "#thislevel = 40\n",
    "print('Finding matching geographies...')\n",
    "#geolist = find_geography4(geo_df, geos, wantlevels)\n",
    "#print('Geographies found: ',geolist)\n",
    "#for y in geolist:\n",
    "#    print(y, geo_df['NAME'].loc[y])\n",
    "\n",
    "\n",
    "#geolist = geo_df['GEOID'][geo_df['GEOID'].apply(lambda x: (('000US' in x[2:7]) & (len(x) == 9)))].tolist()\n",
    "#print(geolist)\n",
    "\n",
    "geolist_df = geo_df[(geo_df['SUMLEVEL'] == thislevel)]\n",
    "#geolist_df = geo_df[(geo_df['SUMLEVEL'] == 40) & (geo_df['GEOID'].apply(lambda x: str(x)[0:5] == '04000'))]#.values.tolist()\n",
    "geolist = geolist_df['GEOID'].values.tolist()\n",
    "print('Data loaded for {:,.0f} geographies!'.format(len(geolist)))\n",
    "\n",
    "#geolist_df[['SUMLEVEL', 'STUSAB', 'STATE', 'LOGRECNO', 'NAME']][geolist_df['STUSAB'] == 'FL']\n",
    "#geolist_df.groupby('STUSAB').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#statedir = '/home/idies/workspace/raddick_census/geography/STATE/'\n",
    "#statefile = statedir + 'tl_2016_us_state.shp'\n",
    "#states_geo = gpd.read_file(statefile)\n",
    "\n",
    "cddir = '/home/idies/workspace/raddick_census/geography/CD/'\n",
    "cdfile = cddir + 'tl_2016_us_cd115.shp'\n",
    "cd_geo = gpd.read_file(cdfile)\n",
    "print('Geographies read')\n",
    "\n",
    "cd_geo = cd_geo.rename(columns={'GEOID': 'GEOID_OLD'})\n",
    "cd_geo['GEOID'] = cd_geo['GEOID_OLD'].apply(lambda x: '50000US'+x)\n",
    "cd_geo = cd_geo.set_index('GEOID',drop=False)\n",
    "\n",
    "cd_geo['STATEFP'] = pandas.to_numeric(cd_geo['STATEFP'], downcast='integer', errors='coerce')\n",
    "\n",
    "cd_geo['undefined'] = False\n",
    "#50000US09ZZ: Congressional Districts not defined\n",
    "#50000US17ZZ: Congressional Districts not defined\n",
    "#50000US26ZZ: Congressional Districts not defined\n",
    "cd_geo.loc['50000US09ZZ','undefined'] = True\n",
    "cd_geo.loc['50000US17ZZ','undefined'] = True\n",
    "cd_geo.loc['50000US26ZZ','undefined'] = True\n",
    "\n",
    "cd_geo['nonvoting'] = False\n",
    "#50000US1198: DC\n",
    "#50000US7298: Puerto Rico\n",
    "#50000US6098: American Samoa\n",
    "#50000US6698: Guam\n",
    "#50000US6998: Northern Mariana Islands\n",
    "#50000US7898: Virgin Islands\n",
    "cd_geo.loc['50000US1198','nonvoting'] = True\n",
    "cd_geo.loc['50000US7298','nonvoting'] = True\n",
    "cd_geo.loc['50000US6098','nonvoting'] = True\n",
    "cd_geo.loc['50000US6698','nonvoting'] = True\n",
    "cd_geo.loc['50000US6998','nonvoting'] = True\n",
    "cd_geo.loc['50000US7898','nonvoting'] = True\n",
    "\n",
    "cd_geo['STUSAB'] = cd_geo.merge(statecodes_df, how='left', left_on='STATEFP', right_on='STATE')['STUSAB'].values\n",
    "cd_geo['DISTRICT'] = pandas.to_numeric(cd_geo['CD115FP'], downcast='integer', errors='coerce')\n",
    "\n",
    "cd_geo['DISTRICT'] = pandas.to_numeric(cd_geo['DISTRICT'])\n",
    "\n",
    "#tips.loc[tips['tip'] < 2, 'tip'] *= 2\n",
    "cd_geo.loc[cd_geo['DISTRICT'] == 0, 'DISTRICT'] = 1\n",
    "\n",
    "\n",
    "print('Found {0:.0f} voting and {1:.0f} non-voting members for a total of {2:.0f}, plus {3:.0f} undefined districts.'\n",
    "      .format(len(cd_geo[cd_geo['nonvoting'] == False]), \n",
    "             len(cd_geo[cd_geo['nonvoting'] == True]),\n",
    "             len(cd_geo),\n",
    "             len(cd_geo[cd_geo['undefined'] == True])\n",
    "            )\n",
    "     )\n",
    "\n",
    "print('Keeping only defined districts...')\n",
    "cd_geo = cd_geo[cd_geo['undefined'] == False]\n",
    "cd_geo = cd_geo.drop('undefined', axis=1)\n",
    "\n",
    "print('Keeping only voting members...')\n",
    "cd_geo = cd_geo[cd_geo['nonvoting'] == False]\n",
    "cd_geo = cd_geo.drop('nonvoting', axis=1)\n",
    "\n",
    "cd_geo = cd_geo.set_index('GEOID')\n",
    "cd_geo.index.name = 'GEOID'\n",
    "\n",
    "print('ok')\n",
    "\n",
    "#cd_geo[['undefined','nonvoting','STATEFP','CD115FP','GEOID_OLD','NAMELSAD','LSAD','CDSESSN','MTFCC','FUNCSTAT','ALAND','AWATER','INTPTLAT','INTPTLON']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### GET PERCENT BLACK AND PERCENT FOR THIS GEOGRAPHY...\n",
    "print('Retrieving data...')\n",
    "ourdata_df = get_data(data_df, thelist, geolist)\n",
    "ourdata_df = ourdata_df.join(data_df['NAME'])\n",
    "\n",
    "ourdata_df['percent_black'] = (ourdata_df['B02001_003'] / ourdata_df['B01001_001']) * 100\n",
    "ourdata_df['percent_white'] = (ourdata_df['B02001_002'] / ourdata_df['B01001_001']) * 100\n",
    "\n",
    "print('Calculating geometries...')\n",
    "# For congressional districts...\n",
    "#cd_geo = cd_geo.rename(columns={'GEOID': 'GEOID_OLD'})\n",
    "#cd_geo['GEOID'] = cd_geo['GEOID_OLD'].apply(lambda x: '50000US'+x)\n",
    "#cd_geo = cd_geo.set_index('GEOID', drop=False)\n",
    "#cd_geo = cd_geo.set_index('GEOID')\n",
    "\n",
    "#cd_geo = cd_geo.drop('GEOID_OLD', axis=1)\n",
    "\n",
    "#ourdata_df = ourdata_df.join(cd_geo)\n",
    "\n",
    "thecrs = {'init': 'epsg:4326'}\n",
    "#ourdata_gdf = gpd.GeoDataFrame(ourdata_df, crs=thecrs, geometry=ourdata_gdf['geometry'])\n",
    "ourdata_gdf = gpd.GeoDataFrame(ourdata_df, crs=thecrs, geometry=cd_geo['geometry'])\n",
    "\n",
    "ourdata_gdf = ourdata_gdf.set_index('GEOID', drop=False)\n",
    "ourdata_gdf.index.name = 'GEOID'\n",
    "\n",
    "ourdata_gdf = ourdata_gdf.join(cd_geo[['STUSAB', 'DISTRICT']])\n",
    "\n",
    "maxval_white = ourdata_gdf['percent_white'].max()\n",
    "maxval_black = ourdata_gdf['percent_black'].max()\n",
    "\n",
    "#ourdata_df.sample(1)\n",
    "print('Maximum percent white: {0:.1f}%; Maximum percent black: {1:.1f}%.'.format(maxval_white, maxval_black))\n",
    "\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DISPLAY FOR ONE STATE AT A TIME\n",
    "\n",
    "showstate = 'Alabama'\n",
    "\n",
    "ourdata_gdf = ourdata_gdf_bk\n",
    "\n",
    "ourdata_gdf = ourdata_gdf[ourdata_gdf['NAME'].apply(lambda x: showstate in x)]\n",
    "\n",
    "ourdata_gdf[['GEOID','NAME']]\n",
    "\n",
    "presidential_voting = {'50000US0101': [103364, 192634],\n",
    "                       '50000US0102': [94299, 185505],\n",
    "                       '50000US0103': [93300, 188477],\n",
    "                       '50000US0104': [50722, 233661],\n",
    "                       '50000US0105': [97159, 200571],\n",
    "                       '50000US0106': [86116, 233493],\n",
    "                       '50000US0107': [204586, 83915]}\n",
    "\n",
    "presidential_voting_df = pandas.DataFrame.from_dict(data=presidential_voting, orient='index')\n",
    "presidential_voting_df.columns = ['clinton', 'trump']\n",
    "presidential_voting_df['total'] = presidential_voting_df['clinton'] + presidential_voting_df['trump']\n",
    "\n",
    "presidential_voting_df['percent_clinton'] = (presidential_voting_df['clinton'] / presidential_voting_df['total']) * 100\n",
    "presidential_voting_df['percent_trump'] = (presidential_voting_df['trump'] / presidential_voting_df['total']) * 100\n",
    "    \n",
    "\n",
    "presidential_voting_df.index.name = 'GEOID'\n",
    "presidential_voting_df\n",
    "\n",
    "ourdata_gdf = ourdata_gdf.join(presidential_voting_df)\n",
    "\n",
    "ourdata_gdf = ourdata_gdf.to_crs({'init': 'epsg:26930'})\n",
    "\n",
    "#### DISPLAY BLACK AND WHITE ON TWO SEPARATE MAPS; ALSO SET COORD LIMITS MANUALLY\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(15,12.5))\n",
    "\n",
    "ax1 = ourdata_gdf.plot(ax=ax1, column='percent_black', cmap='Greys', edgecolor='black')\n",
    "#ax1.set_title('Percent \\'one race, black\\' (ACS 2016)', fontsize=12)\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "ax2 = ourdata_gdf.plot(ax=ax2, column='percent_trump', cmap='seismic', edgecolor='black')\n",
    "#ax2.set_title('Percent vote for Trump', fontsize=12)\n",
    "ax2.set_aspect('equal')\n",
    "\n",
    "ax1.tick_params(axis='both', which='both', bottom='off', left='off', labelleft='off', labelbottom='off')\n",
    "ax2.tick_params(axis='both', which='both', bottom='off', left='off', labelleft='off', labelbottom='off')\n",
    "\n",
    "# add colorbar\n",
    "cax1 = fig.add_axes([0.12, 0.08, 0.36, 0.03])\n",
    "sm1 = plt.cm.ScalarMappable(cmap='Greys', norm=plt.Normalize(vmin=0, vmax=100))\n",
    "\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm1._A = []\n",
    "\n",
    "cbar1 = fig.colorbar(sm1, cax=cax1, format='%.0f', ticks=np.arange(0, 110, 10), orientation='horizontal')\n",
    "\n",
    "cax1.tick_params(labelsize=12)\n",
    "cbar1.set_label('Percent Black (2016 ACS)', fontsize=16)\n",
    "\n",
    "# add colorbar\n",
    "cax2 = fig.add_axes([0.545, 0.08, 0.36, 0.03])\n",
    "sm2 = plt.cm.ScalarMappable(cmap='seismic', norm=plt.Normalize(vmin=0, vmax=100))\n",
    "\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm2._A = []\n",
    "\n",
    "cbar2 = fig.colorbar(sm2, cax=cax2, format='%.0f', ticks=np.arange(0, 110, 10), orientation='horizontal')\n",
    "\n",
    "cax2.tick_params(labelsize=12)\n",
    "cbar2.set_label('Percent vote for Trump', fontsize=16)\n",
    "\n",
    "plt.title('Alabama 2016 Presidential election results by congressional district', fontsize=20, position=(-0.05,27.5))\n",
    "plt.show()\n",
    "#print('ok')\n",
    "#gdf = GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "#type(ourdata_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### DISPLAY FOR THE WHOLE U.S.\n",
    "#### DISPLAY BLACK AND WHITE ON TWO SEPARATE MAPS; ALSO SET COORD LIMITS MANUALLY\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, sharex=True, sharey=True, figsize=(15,12.5))\n",
    "\n",
    "# Fine-tune figure; make subplots close to each other and hide x ticks for\n",
    "# all but bottom plot.\n",
    "fig.subplots_adjust(hspace=0.1)\n",
    "\n",
    "#plt.setp([a.get_xticklabels() for a in fig.axes[:-1]], visible=False)\n",
    "\n",
    "ax1 = ourdata_gdf.plot(ax=ax1, column='percent_white', cmap='viridis', edgecolor='white')\n",
    "ax1.set_title('Percent of population self-reporting as \\'one race, white\\'', fontsize=20)\n",
    "\n",
    "ax2 = ourdata_gdf.plot(ax=ax2, column='percent_black', cmap='viridis', edgecolor='white')\n",
    "ax2.set_title('Percent of population self-reporting as \\'one race, black\\'', fontsize=20)\n",
    "\n",
    "ax1.set_xlim(-130, -65)\n",
    "ax1.set_ylim(23,50)\n",
    "\n",
    "ax2.set_xlim(-130, -65)\n",
    "ax2.set_ylim(23,50)\n",
    "\n",
    "ax1.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    left='off',\n",
    "    right='off',\n",
    "    labelleft='off',\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "\n",
    "ax2.tick_params(\n",
    "    axis='both',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom='off',      # ticks along the bottom edge are off\n",
    "    top='off',         # ticks along the top edge are off\n",
    "    left='off',\n",
    "    right='off',\n",
    "    labelleft='off',\n",
    "    labelbottom='off') # labels along the bottom edge are off\n",
    "\n",
    "\n",
    "# add colorbar\n",
    "cax1 = fig.add_axes([0.9, 0.53, 0.03, 0.37])\n",
    "sm1 = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=0, vmax=maxval_white))\n",
    "\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm1._A = []\n",
    "\n",
    "cbar1 = fig.colorbar(sm1, cax=cax1, format='%.0f', ticks=np.arange(0, 100, 10))\n",
    "\n",
    "cax1.tick_params(labelsize=12)\n",
    "cbar1.set_label('Percent', fontsize=16)\n",
    "\n",
    "# add colorbar\n",
    "cax2 = fig.add_axes([0.9, 0.125, 0.03, 0.36875])\n",
    "sm2 = plt.cm.ScalarMappable(cmap='viridis', norm=plt.Normalize(vmin=0, vmax=maxval_black))\n",
    "\n",
    "# fake up the array of the scalar mappable. Urgh...\n",
    "sm2._A = []\n",
    "\n",
    "cbar2 = fig.colorbar(sm2, cax=cax2, format='%.0f', ticks=np.arange(0, 70, 10))\n",
    "\n",
    "cax2.tick_params(labelsize=12)\n",
    "cbar2.set_label('Percent', fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "#print('ok')\n",
    "#gdf = GeoDataFrame(df, crs=crs, geometry=geometry)\n",
    "#type(ourdata_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### EXAMPLE: SIMPLE PLOT OF EARTH COUNTRIES\n",
    "#world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "#world.plot()\n",
    "\n",
    "### EXAMPLE: PLOT ALL COUNTRIES THAT EXTEND INTO THE SOUTHERN HEMPISPHERE\n",
    "#southern_world = world.cx[:, :0]\n",
    "#southern_world.plot(figsize=(10, 3))\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "### EXAMPLE: OVERLAY CITIES ON WORLD MAP\n",
    "#world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "#cities = gpd.read_file(gpd.datasets.get_path('naturalearth_cities'))\n",
    "#cities = cities.to_crs(world.crs)\n",
    "#base = world.plot(color='white', edgecolor='black', figsize=(12,12))\n",
    "#cities.plot(ax=base, marker='o', color='red', markersize=5, figsize=(12,12))\n",
    "#plt.show()\n",
    "\n",
    "### EXAMPLE: COLOR-CODE COUNTRIES BY PER CAPITA GDP\n",
    "#world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "#world = world[(world.pop_est>0) & (world.name!=\"Antarctica\")]\n",
    "#world['gdp_per_cap'] = world.gdp_md_est / world.pop_est\n",
    "#world.plot(column='gdp_per_cap', figsize=(12,12), cmap='OrRd')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "### EXAMPLE: HELLO ED\n",
    "import numpy as np\n",
    "import string\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world = world.set_index('iso_a3')\n",
    "\n",
    "world['ed'] = np.where(world['name'].apply(lambda x: 'ed' in x.lower()),1,0)\n",
    "world['ed']\n",
    "raw_data = [(\"Ed\", 39.299236, -76.609383)]\n",
    "\n",
    "edplace = pandas.DataFrame(raw_data, columns=[\"name\", \"latitude\", \"longitude\"])\n",
    "edplace['geometry'] = [Point(xy) for xy in zip(edplace.longitude, edplace.latitude)]\n",
    "\n",
    "thecrs = {'init': 'epsg:4326'}\n",
    "edplacer = gpd.GeoDataFrame(edplace, crs=thecrs, geometry=\"geometry\")\n",
    "edplacer = edplacer.to_crs(world.crs)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,10))\n",
    "ax.set_aspect('equal')\n",
    "ax1 = world.plot(ax=ax, color='white', edgecolor='black')\n",
    "ax2 = world[world['ed'] == 1].plot(ax=ax, color='yellow')\n",
    "ax3 = edplacer.plot(ax=ax, marker='o', color='red', markersize=32)\n",
    "ax.annotate('ED', xy=(-76.609383, 39.299236), xytext=(-42.5, 35),\n",
    "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
    "             fontsize=22\n",
    "            )\n",
    "plt.xlim(-180, 180)\n",
    "plt.ylim(-90,90)\n",
    "plt.title('hello ed', fontsize=28)\n",
    "\n",
    "plt.xticks(np.arange(-180, 180.01, 45), fontsize=18)\n",
    "plt.xlabel('Longitude', fontsize=20)\n",
    "plt.yticks(np.arange(-90, 90.01, 30), fontsize=18)\n",
    "plt.ylabel('Latitude', fontsize=20)\n",
    "yellow_patch = mpatches.Patch(color='yellow', label=\"Country has 'Ed' in its name (e.g. swEDen)\")\n",
    "plt.legend(handles=[yellow_patch], loc='lower right', fontsize=16)\n",
    "\n",
    "plt.show()\n",
    "#print('ok')\n",
    "#sumlevel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### CARTOPY EXAMPLES\n",
    "\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "#ax.coastlines()\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "#ax = plt.axes(projection=ccrs.Mollweide())\n",
    "#ax.stock_img()\n",
    "#ax.coastlines()\n",
    "#plt.show()\n",
    "\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.stock_img()\n",
    "ax.coastlines()\n",
    "\n",
    "ny_lon, ny_lat = -75, 43\n",
    "delhi_lon, delhi_lat = 77.23, 28.61\n",
    "\n",
    "plt.plot([ny_lon, delhi_lon], [ny_lat, delhi_lat],\n",
    "         color='blue', linewidth=2, marker='o',\n",
    "         transform=ccrs.Geodetic(),\n",
    "         )\n",
    "\n",
    "plt.plot([ny_lon, delhi_lon], [ny_lat, delhi_lat],\n",
    "         color='gray', linestyle='--',\n",
    "         transform=ccrs.PlateCarree(),\n",
    "         )\n",
    "\n",
    "plt.text(ny_lon - 3, ny_lat - 12, 'New York',\n",
    "         horizontalalignment='right',\n",
    "         transform=ccrs.Geodetic())\n",
    "\n",
    "plt.text(delhi_lon + 3, delhi_lat - 12, 'Delhi',\n",
    "         horizontalalignment='left',\n",
    "         transform=ccrs.Geodetic())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#POPULATION BY CENSUS REGION\n",
    "data_df['SUMLEVEL'] = data_df['GEOID'].apply(lambda x: int(x[0:3]))\n",
    "\n",
    "print('Estimated U.S. population: {0:,.0f}'.format(data_df['B01001_001'].loc['01000US']))\n",
    "\n",
    "print('For the four census regions: {0:,.0f}'.format(data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:7]) == '02000US'].sum()))\n",
    "print('\\n')\n",
    "print('Population by census region:')\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US1'], data_df['B01001_001'].loc['02000US1']))\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US2'], data_df['B01001_001'].loc['02000US2']))\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US3'], data_df['B01001_001'].loc['02000US3']))\n",
    "print('{0:} {1:,.0f}'.format(data_df['NAME'].loc['02000US4'], data_df['B01001_001'].loc['02000US4']))\n",
    "\n",
    "#print('Men: {0:,.0f} (error: {1:,.0f})'.format(data_df['B01001_002'].loc['01000US'], error_df['B01001_002'].loc['01000US']))\n",
    "#print('Women: {0:,.0f} (error: {1:,.0f})'.format(data_df['B01001_026'].loc['01000US'], error_df['B01001_026'].loc['01000US']))\n",
    "\n",
    "#print('Margin of error: {0:,.0f}'.format(error_df['B01001_001'].loc['01000US']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# POPULATION BY STATE\n",
    "data_df[data_df['SUMLEVEL'] == 40]\n",
    "\n",
    "display(HTML('<h2>Population by state</h2>'))\n",
    "\n",
    "statetable = '<table><tr><th>State</th><th>Population</th></tr>'\n",
    "for thisgeoid, thisrow in data_df[data_df['GEOID'].apply(lambda x: x[0:5]) == '04000'].iterrows():\n",
    "    statetable += '<tr>'\n",
    "    statetable += '<td>{0:}</td><td style=\"text-align:right;padding:5px\">{1:,.0f}</td>'.format(thisrow['NAME'], thisrow['B01001_001'])\n",
    "    statetable += '</tr>'\n",
    "statetable += '</table>'\n",
    "\n",
    "display(HTML(statetable))\n",
    "\n",
    "total_population = data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:5]) == '04000'].sum()\n",
    "\n",
    "display(HTML(('TOTAL of all 50 states: <b>{0:,.0f}</b> (not equal to national b/c military etc. is federal)'.format(total_population))))\n",
    "#print('For the four census regions: {0:,.0f}'.format(data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:7]) == '02000US'].sum()))\n",
    "#data_df['B01001_001'][data_df['GEOID'].apply(lambda x: x[0:7]) == '02000US']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
