{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In directory: /home/idies/workspace/persistent/censusdata/microdata\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2885, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-1-cf8b5d767b14>\", line 30, in <module>\n",
      "    ftp = FTP('ftp2.census.gov')\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/ftplib.py\", line 118, in __init__\n",
      "    self.connect(host)\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/ftplib.py\", line 156, in connect\n",
      "    self.welcome = self.getresp()\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/ftplib.py\", line 235, in getresp\n",
      "    resp = self.getmultiline()\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/ftplib.py\", line 221, in getmultiline\n",
      "    line = self.getline()\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/ftplib.py\", line 203, in getline\n",
      "    line = self.file.readline(self.maxline + 1)\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/socket.py\", line 576, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1827, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1120, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 301, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 346, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/inspect.py\", line 1454, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/inspect.py\", line 1411, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/inspect.py\", line 671, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/idies/anaconda3/lib/python3.5/inspect.py\", line 713, in getmodule\n",
      "    _filesbymodname[modname] = f\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import zipfile\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas\n",
    "from pprint import pprint\n",
    "from ftplib import FTP\n",
    "\n",
    "pandas.set_option('display.max_colwidth', -1)\n",
    "\n",
    "states = ['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc']\n",
    "states += ['de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in']\n",
    "states += ['ks', 'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn']\n",
    "states += ['mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj']\n",
    "states += ['nm', 'nv', 'ny', 'oh', 'ok', 'or']\n",
    "states += ['pa', 'pr', 'ri', 'sc', 'sd', 'tn', 'tx', 'us']\n",
    "states += ['ut' ,'va', 'vt', 'wa', 'wi', 'wv', 'wy']\n",
    "\n",
    "basedir = '/home/idies/workspace/persistent/censusdata/'\n",
    "#local_dir = '/home/idies/workspace/raddick_acs_data/'\n",
    "pumsdir = basedir + 'microdata/'\n",
    "\n",
    "if not (os.getcwd() == basedir):\n",
    "    os.chdir(basedir)\n",
    "if not (os.path.exists(pumsdir)):\n",
    "    os.makedirs(pumsdir)\n",
    "os.chdir(pumsdir)\n",
    "print('In directory: '+os.getcwd())\n",
    "\n",
    "ftp = FTP('ftp2.census.gov')\n",
    "ftp.login()\n",
    "print(ftp.getwelcome())\n",
    "#print(ftp.dir())\n",
    "ftp.cwd('programs-surveys/acs/data/pums/2016/1-Year/')\n",
    "print(ftp.nlst())\n",
    "#thefilename = 'All_Geographies.zip'\n",
    "#with open(thefilename, 'wb') as f:\n",
    "#    ftp.retrbinary('RETR {0:}'.format(thefilename), f.write)\n",
    "ftp.quit()\n",
    "print('Done')\n",
    "\n",
    "#dirurl = 'https://www2.census.gov/programs-surveys/acs/data/pums/2016/1-Year/'\n",
    "\n",
    "#print('Writing zipfiles...')\n",
    "#for onestate in states:\n",
    "#    filename = 'csv_p{0:}.zip'.format(onestate)\n",
    "#    remotefilename = dirurl + filename\n",
    "#    localfilename = data_dir + filename\n",
    "##    print('Reading {0:}'.format(remotefilename))\n",
    "#    response = urllib.request.urlopen(remotefilename)\n",
    "#    downloadedfile = response.read()\n",
    "#    if (onestate in ('ak', 'fl', 'oh', 'tx', 'us', 'wy')):\n",
    "#        print('Writing {0:}...'.format(filename))\n",
    "#    with open(localfilename, 'wb') as f:\n",
    "#        f.write(downloadedfile)\n",
    "        \n",
    "\n",
    "    \n",
    "#    print('Reading file...')\n",
    "#downloadedfile = response.read()\n",
    "    \n",
    "#print('Writing zipfile...')\n",
    "#with open('All_Geographies.zip', 'wb') as f:\n",
    "#    f.write(downloadedfile)\n",
    "\n",
    "#print('Reading zipfile...')\n",
    "#thezipfile = zipfile.ZipFile('All_Geographies.zip')\n",
    "\n",
    "#print('Extracting files...')\n",
    "#thezipfile.extractall()\n",
    "\n",
    "#thezipfile.close()\n",
    "\n",
    "#print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Extracting files...')        \n",
    "for onestate in states:\n",
    "    thezipfilename = data_dir + 'csv_p{0:}.zip'.format(onestate)\n",
    "    print(thezipfilename)\n",
    "    thezipfile = zipfile.ZipFile(thezipfilename)    \n",
    "    thezipfile.extractall()\n",
    "    thezipfile.close()\n",
    "    os.remove(thezipfilename)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from pprint import pprint\n",
    "import json\n",
    "x_df = pandas.read_csv('microdata/ss16pri.csv', low_memory=False)\n",
    "x_df = x_df.set_index('SERIALNO', drop=False)\n",
    "\n",
    "# Capitalize names of all columns for consistency with metadata file\n",
    "col_list = x_df.columns\n",
    "new_col_list = []\n",
    "for i in range(0, len(col_list)):\n",
    "    new_col_list.append(col_list[i].upper())\n",
    "x_df[new_col_list] = x_df[col_list]\n",
    "\n",
    "x_df.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_columns_list = x_df.sample(1).columns.sort_values().tolist()\n",
    "for i in range(0, len(data_columns_list)):\n",
    "    data_columns_list[i] = data_columns_list[i].upper()\n",
    "data_columns_list.sort()\n",
    "print('Columns in the person microdata:')\n",
    "data_columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# PARSE METADATA\n",
    "with open('microdata/pums_metadata_person.txt', 'rt', encoding='utf-8') as f:\n",
    "    read_data = f.readlines()\n",
    "f.close()\n",
    "\n",
    "variables = {}\n",
    "varnames = []\n",
    "vardescription = []\n",
    "newvarline = -1\n",
    "counter = 0\n",
    "for aline in read_data:\n",
    "#    print(aline)\n",
    "    maybevarname = aline.strip().split(' ')[0]\n",
    "    \n",
    "    if ((aline.isupper()) | ('UNEDITED' in aline)):                            # if the entire line is uppercase...\n",
    "        thisvar = aline.strip().split('\\t')             # it's a variable, whose name is the text up to the first tab...\n",
    "        if not(thisvar[0].strip()[0].isnumeric()):      #  except that some all-caps lines are value codes starting with numbers\n",
    "            newvarline = counter                        # ALSO, this is the start of a new variable group, so record its line number...\n",
    "            thisvarname = thisvar[0].strip()\n",
    "            variables[thisvarname] = {}\n",
    "            variables[thisvarname]['name'] = thisvar[0].strip()\n",
    "    if ((counter - newvarline) == 1):\n",
    "        variables[thisvarname]['description'] = aline.strip()\n",
    "    if ((counter - newvarline) >= 2):\n",
    "        if (len(aline) > 0):\n",
    "            valueslist = aline.strip().split(' .')\n",
    "            if (len(valueslist) == 1):\n",
    "                if (len(valueslist[0]) > 0):\n",
    "                    variables[thisvarname]['note'] = aline.strip()\n",
    "#                    print('note: ', valueslist[0])\n",
    "            else:\n",
    "#                print('...and then....', valueslist)\n",
    "                variables[thisvarname]['values'] = {}\n",
    "                for j in range(0,7):\n",
    "                    variables[thisvarname]['values'][j] = j * 3\n",
    "\n",
    "#        print('..........and then: ',aline)\n",
    "    counter = counter + 1                            # increment the counter\n",
    "    \n",
    "metadata_columns_list = []\n",
    "for (key, value) in variables.items():\n",
    "    metadata_columns_list.append(key)\n",
    "metadata_columns_list.sort()\n",
    "print('Metadata about person microdata, parsed from pums_metadata_person.txt:')\n",
    "print(metadata_columns_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Verify that the columns are the same in data and metadata\n",
    "\n",
    "print('Columns in data list: {0:,.0f}'.format(len(data_columns_list)))\n",
    "print('Columns in metadata list: {0:,.0f}'.format(len(metadata_columns_list)))\n",
    "\n",
    "for z in metadata_columns_list:\n",
    "    if (z not in data_columns_list):\n",
    "        print(z)\n",
    "        \n",
    "for z in data_columns_list:\n",
    "    if (z not in metadata_columns_list):\n",
    "        print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# NEXT: How do we get the metadata to save in the same order?\n",
    "better_search_order = np.empty((len(x_df.columns),2), dtype=object)\n",
    "counter = 0\n",
    "current_columns = x_df.columns.tolist()\n",
    "for i in range(0, len(better_search_order)):\n",
    "    better_search_order[i,0] = current_columns[i]\n",
    "    better_search_order[i,1] = counter\n",
    "    counter = counter + 1\n",
    "better_search_order_df = pandas.DataFrame(better_search_order, columns={'column_name','sort_order'})\n",
    "\n",
    "better_search_order_df = better_search_order_df.set_index('column_name')\n",
    "better_search_order_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for (thiskey, thisvalue) in variables.items():\n",
    "    variables[thiskey]['sort_order'] = better_search_order_df['sort_order'].loc[thiskey]\n",
    "#pprint(variables)\n",
    "variables_json = json.dumps(variables)\n",
    "with open('/home/idies/workspace/raddick_acs_data/microdata_variables_person.json', 'w') as f:\n",
    "    f.write(variables_json)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x_df.to_csv('/home/idies/workspace/raddick_acs_data/microdata_person.csv')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_df = pandas.read_csv('/home/idies/workspace/raddick_acs_data/microdata_person.csv', index_col=0)\n",
    "y_df = y_df.rename(columns={'SERIALNO.1': 'SERIALNO'})\n",
    "#y_df.head(1)\n",
    "\n",
    "with open('/home/idies/workspace/raddick_acs_data/microdata_variables_person.json', 'r') as f:\n",
    "    z = f.read()\n",
    "    \n",
    "mdf_dict = json.loads(z)\n",
    "pprint(mdf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
